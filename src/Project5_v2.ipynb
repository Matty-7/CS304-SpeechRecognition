{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multivariate_normal  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeech\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DoubleArray, FloatArray\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeech\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproject2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NUMBERS\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeech\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproject3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     HARD_TEMPLATE_INDEXES,\n\u001b[0;32m     16\u001b[0m     HARD_TEST_INDEXES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     boosted_mfcc_from_file,\n\u001b[0;32m     21\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'speech'"
     ]
    }
   ],
   "source": [
    "\"\"\"Run with `python3 -m speech.project5.hmm`.\"\"\"\n",
    "\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from logging import debug\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from scipy.stats import multivariate_normal  # type: ignore\n",
    "from sklearn.cluster import KMeans  # type: ignore\n",
    "\n",
    "from speech import DoubleArray, FloatArray\n",
    "from speech.project2.main import NUMBERS\n",
    "from speech.project3 import (\n",
    "    HARD_TEMPLATE_INDEXES,\n",
    "    HARD_TEST_INDEXES,\n",
    "    INF_FLOAT32,\n",
    "    TEMPLATE_INDEXES,\n",
    "    TEST_INDEXES,\n",
    "    boosted_mfcc_from_file,\n",
    ")\n",
    "\n",
    "MINUS_INF = -INF_FLOAT32\n",
    "\n",
    "\n",
    "def multivariate_gaussian_negative_log_pdf_diag_cov(\n",
    "    x: FloatArray, mean: FloatArray, cov: DoubleArray\n",
    "):\n",
    "    return -np.log(multivariate_gaussian_pdf_diag_cov(x, mean, cov))\n",
    "\n",
    "\n",
    "def multivariate_gaussian_pdf_diag_cov(\n",
    "    x: FloatArray, mean: FloatArray, cov: DoubleArray\n",
    ") -> np.float64:\n",
    "    \"\"\"\n",
    "    Compute the probability density function (PDF) of a multivariate Gaussian distribution with a diagonal covariance matrix.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    if len(cov.shape) == 2:\n",
    "        cov = np.diag(cov)\n",
    "    det_covariance = np.prod(cov)\n",
    "    inv_covariance_matrix = np.diag(1 / cov)\n",
    "\n",
    "    difference_vector = x - mean\n",
    "    exponent = np.dot(\n",
    "        np.dot(difference_vector, inv_covariance_matrix), difference_vector\n",
    "    )\n",
    "\n",
    "    normalization = (2 * np.pi) ** (n / 2) * np.sqrt(det_covariance)\n",
    "\n",
    "    pdf = 1 / normalization * np.exp(-0.5 * exponent)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def align_sequence(sequence, means, covariances, transition_probs):\n",
    "    num_states = len(means)\n",
    "    sequence_length = len(sequence)\n",
    "\n",
    "    viterbi_trellis = np.full((num_states, sequence_length), MINUS_INF)\n",
    "    backpointers = np.zeros((num_states, sequence_length), dtype=int)\n",
    "\n",
    "    np.seterr(divide=\"ignore\")\n",
    "\n",
    "    # wait until positive probability\n",
    "    start_index = -1\n",
    "    while True:\n",
    "        start_index += 1\n",
    "\n",
    "        if start_index > 5:\n",
    "            return [0] * len(sequence), MINUS_INF\n",
    "\n",
    "        log_probabilities = (\n",
    "            multivariate_normal.logpdf(\n",
    "                sequence[start_index], mean=mean, cov=cov, allow_singular=True\n",
    "            )\n",
    "            for mean, cov in zip(means[0], covariances[0])\n",
    "        )\n",
    "        viterbi_trellis[0, start_index] = max(log_probabilities)\n",
    "\n",
    "        if viterbi_trellis[0, start_index] != MINUS_INF:\n",
    "            break\n",
    "\n",
    "    for t in range(start_index + 1, sequence_length):\n",
    "        for state in range(num_states):\n",
    "            last_viterbi_trellis = viterbi_trellis[:, t - 1]\n",
    "            log_transition_prob = np.log(transition_probs[:, state])\n",
    "            if all(\n",
    "                np.logical_or(\n",
    "                    last_viterbi_trellis == MINUS_INF,\n",
    "                    log_transition_prob == MINUS_INF,\n",
    "                )\n",
    "            ):\n",
    "                \"\"\"last_viterbi_trellis or log_transition_prob is -inf\"\"\"\n",
    "                viterbi_trellis[state, t] = MINUS_INF\n",
    "            else:\n",
    "                emission_log_prob = np.log(\n",
    "                    max(\n",
    "                        multivariate_gaussian_pdf_diag_cov(\n",
    "                            sequence[t], mean=mean, cov=cov\n",
    "                        )\n",
    "                        for mean, cov in zip(means[state], covariances[state])\n",
    "                    )\n",
    "                )\n",
    "                viterbi_scores = (\n",
    "                    last_viterbi_trellis + log_transition_prob + emission_log_prob\n",
    "                )\n",
    "\n",
    "                viterbi_trellis[state, t] = np.max(viterbi_scores)\n",
    "                backpointers[state, t] = np.argmax(viterbi_scores)\n",
    "\n",
    "    # Trace back\n",
    "    # alignment = [np.argmax(viterbi_trellis[:, -1])]\n",
    "    # start from last state, not highest score state\n",
    "    path = [num_states - 1]\n",
    "    for t in range(sequence_length - 1, 0, -1):\n",
    "        path.append(backpointers[path[-1], t])\n",
    "\n",
    "    path.reverse()\n",
    "    return path, viterbi_trellis[-1, -1]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HMMState:\n",
    "    means: list[FloatArray]\n",
    "    \"\"\"n_gaussians of mean vectors. Also used for K-means iteration.\"\"\"\n",
    "    covariances: list[DoubleArray]\n",
    "    \"\"\"n_gaussians of diagonal of covariance matrix\"\"\"\n",
    "    weights: list[float]\n",
    "    transition_loss: dict[\"HMMState\", float]\n",
    "    \"\"\"Negative log transition probability.\"\"\"\n",
    "    nth_state: int\n",
    "    label: int | None\n",
    "    \"\"\"The digit associated with the state.\n",
    "    `None` if the state is the first state.\"\"\"\n",
    "    exit_loss: float = 0.0\n",
    "    \"\"\"Negative log probability to exit the HMM, positive only if is last state\n",
    "    of a digit.\"\"\"\n",
    "    parent: \"HMMState | None\" = None\n",
    "    \"\"\"The state is the first state if the `parent` is `None`.\"\"\"\n",
    "\n",
    "    def is_non_emiting(self):\n",
    "        return len(self.means) == 0\n",
    "\n",
    "    @classmethod\n",
    "    def root(cls):\n",
    "        return cls(\n",
    "            means=[],\n",
    "            covariances=[],\n",
    "            weights=[],\n",
    "            transition_loss={},\n",
    "            nth_state=-1,\n",
    "            label=None,\n",
    "        )\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return id(self)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"HMMState{id(self)}(`{self.label}` with {len(self.means)} Gaussians)\"\n",
    "\n",
    "\n",
    "def clone_hmm_states(hmm_states: list[HMMState]):\n",
    "    \"\"\"Clone a series of HMMStates preserving their relationships.\"\"\"\n",
    "    state_map: dict[HMMState, HMMState] = {}\n",
    "    new_states: list[HMMState] = []\n",
    "    for state in hmm_states:\n",
    "        new_state = HMMState(\n",
    "            means=state.means,\n",
    "            covariances=state.covariances,\n",
    "            transition_loss=state.transition_loss,\n",
    "            nth_state=state.nth_state,\n",
    "            weights=state.weights,\n",
    "            label=state.label,\n",
    "            parent=state.parent,\n",
    "        )\n",
    "        state_map[state] = new_state\n",
    "        new_states.append(new_state)\n",
    "\n",
    "    for new_state in new_states:\n",
    "        new_state.transition_loss = {\n",
    "            state_map.get(state, state): prob\n",
    "            for state, prob in new_state.transition_loss.items()\n",
    "        }\n",
    "        if new_state.parent is not None:\n",
    "            new_state.parent = state_map.get(new_state.parent, new_state.parent)\n",
    "    return new_states\n",
    "\n",
    "\n",
    "def _align_sequence_round(\n",
    "    sample: FloatArray | None,\n",
    "    hmm_state: HMMState,\n",
    "    round_min_loss: float,\n",
    "    prev_losses: dict[HMMState, \"LossNode\"],\n",
    "    current_losses: dict[HMMState, \"LossNode\"],\n",
    "    beam_width: float,\n",
    "):\n",
    "    \"\"\"Aligning non-emitting state if `sample` is `None`.\"\"\"\n",
    "    # Similar to `Trie._match_word_round`.\n",
    "    min_loss = np.inf\n",
    "    min_loss_node: LossNode | None = None\n",
    "\n",
    "    for from_node, cost in hmm_state.transition_loss.items():\n",
    "        if prev_loss_node := prev_losses.get(from_node):\n",
    "            accumulated_loss = cost + prev_loss_node.loss\n",
    "            if accumulated_loss < min_loss:\n",
    "                min_loss = accumulated_loss\n",
    "                min_loss_node = prev_loss_node\n",
    "\n",
    "    if min_loss_node is not None and min_loss < round_min_loss + beam_width:\n",
    "        if sample is None:\n",
    "            combined_min_loss = min_loss\n",
    "        else:\n",
    "            # weighted gaussians\n",
    "            assert (\n",
    "                len(hmm_state.means)\n",
    "                == len(hmm_state.covariances)\n",
    "                == len(hmm_state.weights)\n",
    "            )\n",
    "            emission_loss = (\n",
    "                min(\n",
    "                    multivariate_gaussian_negative_log_pdf_diag_cov(\n",
    "                        sample, mean=mean, cov=cov\n",
    "                    )\n",
    "                    - np.log(weight)\n",
    "                    for mean, cov, weight in zip(\n",
    "                        hmm_state.means, hmm_state.covariances, hmm_state.weights\n",
    "                    )\n",
    "                )\n",
    "                if len(hmm_state.means) > 0\n",
    "                else 0\n",
    "            )\n",
    "            combined_min_loss = min_loss + emission_loss\n",
    "\n",
    "        if combined_min_loss < round_min_loss + beam_width:\n",
    "            round_min_loss = min(round_min_loss, combined_min_loss)\n",
    "            new_loss_node = min_loss_node.copying_update(\n",
    "                state_node=hmm_state,\n",
    "                loss=combined_min_loss,\n",
    "                prev_end_loss_node=(\n",
    "                    min_loss_node\n",
    "                    if sample is None  # Non-emitting state\n",
    "                    else min_loss_node.prev_end_loss_node\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            current_losses[hmm_state] = new_loss_node\n",
    "\n",
    "    return round_min_loss\n",
    "\n",
    "\n",
    "def _align_sequence_and_hmm_states(\n",
    "    sequence: FloatArray,\n",
    "    non_emitting_states: list[HMMState],\n",
    "    emitting_states: list[HMMState],\n",
    "    beam_width=1000.0,\n",
    "):\n",
    "    \"\"\"Align a sequence against a sequence of HMM states.\n",
    "    The first non-emitting state should be the beginning state.\"\"\"\n",
    "    np.seterr(divide=\"ignore\")\n",
    "\n",
    "    # Similar to `Trie._match_word`.\n",
    "    prev_losses: dict[HMMState, LossNode] = {\n",
    "        non_emitting_states[0]: LossNode(state_node=non_emitting_states[0])\n",
    "    }\n",
    "\n",
    "    for sample in sequence:\n",
    "        intermediate_losses: dict[HMMState, LossNode] = {}\n",
    "        round_min_loss = np.inf\n",
    "        for state in non_emitting_states:\n",
    "            round_min_loss = _align_sequence_round(\n",
    "                None,\n",
    "                state,\n",
    "                round_min_loss,\n",
    "                prev_losses,\n",
    "                intermediate_losses,\n",
    "                beam_width,\n",
    "            )\n",
    "        debug(\"intermediate_losses=%s\", intermediate_losses)\n",
    "        for state, intermediate_loss in intermediate_losses.items():\n",
    "            if (\n",
    "                prev_losses.get(state) is None # beginning state\n",
    "                or intermediate_loss.loss < prev_losses[state].loss\n",
    "            ):\n",
    "                prev_losses[state] = intermediate_loss\n",
    "\n",
    "        current_losses: dict[HMMState, LossNode] = {}\n",
    "        round_min_loss = np.inf\n",
    "        for state in emitting_states:\n",
    "            round_min_loss = _align_sequence_round(\n",
    "                sample,\n",
    "                state,\n",
    "                round_min_loss,\n",
    "                prev_losses,\n",
    "                current_losses,\n",
    "                beam_width,\n",
    "            )\n",
    "        debug(\"current_losses=%s\", current_losses)\n",
    "\n",
    "        round_threshold = round_min_loss + beam_width\n",
    "        prev_losses = {\n",
    "            node: loss_node\n",
    "            for node, loss_node in current_losses.items()\n",
    "            if loss_node.loss <= round_threshold\n",
    "        }\n",
    "        debug(\"Filtered previous_losses=%s\", prev_losses)\n",
    "\n",
    "    final_losses: dict[HMMState, LossNode] = {}\n",
    "    for state in non_emitting_states:\n",
    "        _ = _align_sequence_round(\n",
    "            None,\n",
    "            state,\n",
    "            np.inf,\n",
    "            prev_losses,\n",
    "            final_losses,\n",
    "            beam_width,\n",
    "        )\n",
    "    return prev_losses, final_losses\n",
    "\n",
    "\n",
    "def match_sequence_against_hmm_states(\n",
    "    sequence: FloatArray,\n",
    "    non_emitting_states: list[HMMState],\n",
    "    emitting_states: list[HMMState],\n",
    "    beam_width=1000.0,\n",
    "):\n",
    "    \"\"\"Match a sequence against a sequence of HMM states.\n",
    "    The first non-emitting state should be the beginning state,\n",
    "    and the last non-emitting state should be the end state.\"\"\"\n",
    "    _, last_losses = _align_sequence_and_hmm_states(\n",
    "        sequence, non_emitting_states, emitting_states, beam_width\n",
    "    )\n",
    "    debug(\"last_losses=%s\", last_losses)\n",
    "\n",
    "    min_finished_loss_node = last_losses[non_emitting_states[-1]]\n",
    "    return min_finished_loss_node.backtrack()\n",
    "\n",
    "\n",
    "def align_sequence_train(\n",
    "    sequence: FloatArray,\n",
    "    hmm_states: list[HMMState],\n",
    "):\n",
    "    \"\"\"align a sequence vs a hmm model\"\"\"\n",
    "    sequence_length = len(sequence)\n",
    "\n",
    "    np.seterr(divide=\"ignore\")\n",
    "\n",
    "    # initialize prev_losses with first state\n",
    "    prev_losses: dict[HMMState, LossNode] = {\n",
    "        hmm_states[0]: LossNode(\n",
    "            state_node=hmm_states[0],\n",
    "            prev_end_loss_node=None,\n",
    "            loss=min(\n",
    "                multivariate_gaussian_negative_log_pdf_diag_cov(\n",
    "                    sequence[0], mean=mean, cov=cov\n",
    "                )\n",
    "                - np.log(weight)\n",
    "                for mean, cov, weight in zip(\n",
    "                    hmm_states[0].means,\n",
    "                    hmm_states[0].covariances,\n",
    "                    hmm_states[0].weights,\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    }\n",
    "\n",
    "    current_losses: dict[HMMState, LossNode] = {}\n",
    "    for t in range(1, sequence_length):\n",
    "        current_losses = {}\n",
    "        for node in hmm_states:\n",
    "            combined_losses: list[tuple[LossNode, float]] = []\n",
    "            for k, v in node.transition_loss.items():\n",
    "                if l := prev_losses.get(k):\n",
    "                    combined_losses.append((l, v + l.loss))\n",
    "\n",
    "            if len(combined_losses) > 0:\n",
    "                emission_loss = min(\n",
    "                    multivariate_gaussian_negative_log_pdf_diag_cov(\n",
    "                        sequence[t], mean=mean, cov=cov\n",
    "                    )\n",
    "                    - np.log(weight)\n",
    "                    for mean, cov, weight in zip(\n",
    "                        node.means, node.covariances, node.weights\n",
    "                    )\n",
    "                )\n",
    "                best_loss_node, min_loss = min(combined_losses, key=lambda x: x[1])\n",
    "                current_losses.update(\n",
    "                    {\n",
    "                        node: LossNode(\n",
    "                            state_node=node,\n",
    "                            prev_end_loss_node=best_loss_node,\n",
    "                            loss=min_loss + emission_loss,\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        prev_losses = current_losses\n",
    "\n",
    "    # backtrack\n",
    "    prev_loss = list(current_losses.values())[-1]\n",
    "    alignment = [prev_loss.state_node.nth_state]\n",
    "    while maybe_prev := prev_loss.prev_end_loss_node:\n",
    "        prev_loss = maybe_prev\n",
    "        alignment.append(prev_loss.state_node.nth_state)\n",
    "\n",
    "    alignment.reverse()\n",
    "\n",
    "    return alignment, list(current_losses.values())[-1].loss\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LossNode:\n",
    "    state_node: HMMState\n",
    "    prev_end_loss_node: \"LossNode | None\" = None\n",
    "    loss: float = 0.0\n",
    "\n",
    "    def copying_update(\n",
    "        self,\n",
    "        state_node: HMMState | None = None,\n",
    "        prev_end_loss_node: \"LossNode | None\" = None,\n",
    "        loss: float | None = None,\n",
    "    ):\n",
    "        if state_node is None:\n",
    "            state_node = self.state_node\n",
    "        if prev_end_loss_node is None:\n",
    "            prev_end_loss_node = self.prev_end_loss_node\n",
    "        if loss is None:\n",
    "            loss = self.loss\n",
    "\n",
    "        return LossNode(state_node, prev_end_loss_node, loss)\n",
    "\n",
    "    def backtrack(self) -> list[int]:\n",
    "        reversed_words = []\n",
    "        current: \"LossNode | None\" = self\n",
    "        while current is not None:\n",
    "            word = current.state_node.label\n",
    "            if word is not None:\n",
    "                reversed_words.append(word)\n",
    "            current = current.prev_end_loss_node\n",
    "        return list(reversed(reversed_words))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        prev_end_loss_node = (\n",
    "            self.prev_end_loss_node.state_node if self.prev_end_loss_node else None\n",
    "        )\n",
    "        return f\"LossNode({self.state_node}, prev_end_loss_node={prev_end_loss_node} loss={self.loss:.2f})\"\n",
    "\n",
    "\n",
    "class HMM_Single:\n",
    "    root: HMMState\n",
    "    n_states: int\n",
    "    transition_matrix: NDArray[np.float64]\n",
    "    grouped_data: NDArray[np.int64]\n",
    "    label: int\n",
    "    states: list[HMMState]\n",
    "    _raw_data: list[FloatArray]\n",
    "    _slice_array: NDArray\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        label: int,\n",
    "        data: list[FloatArray],\n",
    "        n_states=5,\n",
    "        n_gaussians=4,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fits the model to the provided training data using segmental K-means.\n",
    "\n",
    "        Parameters:\n",
    "        data: The training data.\n",
    "            It should have the shape (N, l) or (N, l, d), where N is the number of training samples\n",
    "            and l is the length of each training sample.\n",
    "            Each training sample can be a scalar or a vector.\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        self._raw_data = data\n",
    "        self.n_states = n_states\n",
    "        self.n_samples = len(data)\n",
    "        self.transition_matrix = np.zeros((n_states, n_states))\n",
    "        self.states = []\n",
    "        parent = None\n",
    "        for s in range(self.n_states):\n",
    "            state = HMMState(\n",
    "                parent=parent,\n",
    "                means=[],\n",
    "                covariances=[],\n",
    "                weights=[],\n",
    "                transition_loss={},\n",
    "                nth_state=s,\n",
    "                exit_loss=0,\n",
    "                label=self.label,\n",
    "            )\n",
    "            parent = state\n",
    "            self.states.append(state)\n",
    "\n",
    "        self._init()\n",
    "\n",
    "        prev_groups = None\n",
    "        current_n_gaussians = 1\n",
    "        while current_n_gaussians <= n_gaussians:\n",
    "            self._update(current_n_gaussians)\n",
    "            if prev_groups is not None and np.all(prev_groups == self.grouped_data):\n",
    "                # Converge.\n",
    "                current_n_gaussians *= 2\n",
    "            prev_groups = self.grouped_data\n",
    "\n",
    "    def _init(self):\n",
    "        ls = [_.shape[0] for _ in self._raw_data]\n",
    "        self.grouped_data = np.array(\n",
    "            [np.linspace(0, l, self.n_states + 1).astype(int) for l in ls]\n",
    "        )\n",
    "\n",
    "    def _update(self, n_gaussians: int):\n",
    "        self._calculate_slice_array()\n",
    "        self._calculate_mean_variance(n_gaussians)\n",
    "        self._calculate_transition_matrix()\n",
    "\n",
    "        # transition loss\n",
    "        for s in range(self.n_states):\n",
    "            self.states[s].transition_loss = {\n",
    "                self.states[i]: -np.log(v)\n",
    "                for i, v in enumerate(self.transition_matrix[:, s])\n",
    "                if v > 0\n",
    "            }\n",
    "        # exit prob\n",
    "        self.states[-1].exit_loss = -np.log(1 - np.sum(self.transition_matrix[-1]))\n",
    "\n",
    "        alignment_result = []\n",
    "        for i in range(self.n_samples):\n",
    "            a, _ = align_sequence_train(self._raw_data[i], self.states)\n",
    "            alignment_result.append(a)\n",
    "        self.grouped_data = np.array(\n",
    "            list(map(lambda x: self._state_list_2_grouped_data(x), alignment_result))\n",
    "        )\n",
    "\n",
    "    def _state_list_2_grouped_data(self, a):\n",
    "        prev = a[0]\n",
    "        r = [prev]\n",
    "        for id, i in enumerate(a):\n",
    "            if prev != i:\n",
    "                r.append(id)\n",
    "            prev = i\n",
    "        r.append(len(a))\n",
    "        return r\n",
    "\n",
    "    def _calculate_slice_array(self):\n",
    "        self._slice_array = np.asarray(\n",
    "            [\n",
    "                list(map(lambda x: slice(*x), zip(group, group[1:])))\n",
    "                for group in self.grouped_data\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def _calculate_mean_variance(self, n_gaussians: int):\n",
    "        for state in range(self.n_states):\n",
    "            state_slices = self._slice_array[:, state]\n",
    "            state_data = [d[s] for s, d in zip(state_slices, self._raw_data)]\n",
    "            flat_state_data = np.concatenate(state_data)  # (n, 39)\n",
    "            if n_gaussians < 2:\n",
    "                # First K-means iteration\n",
    "                new_means = np.mean(flat_state_data, axis=0)\n",
    "                assert new_means.shape == (39,)\n",
    "                new_means = new_means[np.newaxis, :]\n",
    "                assert new_means.shape == (1, 39)\n",
    "            else:\n",
    "                prev_means_for_state = np.asarray(self.states[state].means)\n",
    "                if prev_means_for_state.shape[0] == n_gaussians:\n",
    "                    # Last iteration with the same `n_gaussians` did not converge\n",
    "                    new_means = prev_means_for_state\n",
    "                else:\n",
    "                    # New iteration with double the `n_gaussians`\n",
    "                    assert prev_means_for_state.shape == (\n",
    "                        n_gaussians / 2,\n",
    "                        39,\n",
    "                    ), (n_gaussians, prev_means_for_state.shape)\n",
    "                    new_means = np.vstack(\n",
    "                        (prev_means_for_state * 0.9, prev_means_for_state * 1.1)\n",
    "                    )\n",
    "            assert new_means.shape == (n_gaussians, 39), new_means.shape\n",
    "            kmeans = KMeans(n_clusters=n_gaussians, init=new_means)  # type: ignore\n",
    "            kmeans = kmeans.fit(flat_state_data)\n",
    "            labels: NDArray[np.int32] | None = kmeans.labels_\n",
    "            assert labels is not None\n",
    "            groups = [\n",
    "                [True if _ == i else False for _ in labels] for i in range(n_gaussians)\n",
    "            ]\n",
    "            weights = [\n",
    "                list(labels).count(elem) / len(labels) for elem in range(n_gaussians)\n",
    "            ]\n",
    "            grouped_flat_state_data = [\n",
    "                flat_state_data[g] for g in groups\n",
    "            ]  # [(n, 39); n_g]\n",
    "            avg = [\n",
    "                np.average(d, axis=0) for d in grouped_flat_state_data\n",
    "            ]  # [(39,); n_g]\n",
    "            var = [\n",
    "                (\n",
    "                    np.diag(np.diag(np.cov(d.T) + 0.1))\n",
    "                    # careful when a state only has one associated frame\n",
    "                    if d.shape[0] != 1\n",
    "                    else np.eye(d.shape[1])\n",
    "                )\n",
    "                for d in grouped_flat_state_data\n",
    "            ]\n",
    "\n",
    "            self.states[state].means = avg\n",
    "            self.states[state].covariances = var\n",
    "            self.states[state].weights = weights\n",
    "\n",
    "    def _calculate_transition_matrix(self):\n",
    "        for i in range(self.n_states):\n",
    "            total = sum([s.stop - s.start for s in self._slice_array[:, i]])\n",
    "            self.transition_matrix[i, i] = (total - self.n_samples) / total\n",
    "            if i + 1 < self.n_states:\n",
    "                self.transition_matrix[i, i + 1] = self.n_samples / total\n",
    "\n",
    "    def predict_score(self, target: FloatArray):\n",
    "        \"\"\"\n",
    "        Take a target sequence and return similarity with the training samples.\n",
    "        \"\"\"\n",
    "        return align_sequence_train(target, self.states)\n",
    "\n",
    "\n",
    "def single_hmm_w_template_file_names(\n",
    "    label: int,\n",
    "    template_file_names: list[str],\n",
    "    n_states: int,\n",
    "    n_gaussians: int,\n",
    "):\n",
    "    template_mfcc_s = [\n",
    "        boosted_mfcc_from_file(file_name) for file_name in template_file_names\n",
    "    ]\n",
    "    return HMM_Single(label, template_mfcc_s, n_states, n_gaussians)\n",
    "\n",
    "\n",
    "class HMM:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_states=5,\n",
    "        n_gaussians=4,\n",
    "        hmm_instances: list[HMM_Single] = [],\n",
    "    ):\n",
    "        self.n_states = n_states\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self._hmm_instances = hmm_instances\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        templates_for_each_label: list[list[FloatArray]],\n",
    "        labels: list[int],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fits the model to the given training data using segmental K-means.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        templates_for_each_label : A list of training samples with length `n_samples`, where each sample is represented as a list of numpy arrays.\n",
    "            The outer list contains different training samples, each corresponding to a target number (e.g., 1, 2, 3).\n",
    "            The inner list represents the number of samples in each target.\n",
    "            Each numpy array is the training data and has a shape of `(l, d)`, where `l` is the number of frames and `d` is the dimension of features (typically 39).\n",
    "\n",
    "        labels : array-like of shape `(n_samples,)`\n",
    "            Target vector relative to X.\n",
    "        \"\"\"\n",
    "        assert len(templates_for_each_label) == len(labels)\n",
    "\n",
    "        for templates, label in zip(templates_for_each_label, labels):\n",
    "            debug(\"Calculating single HMM for number `%s`.\", label)\n",
    "            hmm = HMM_Single(label, templates, self.n_states, self.n_gaussians)\n",
    "            self._hmm_instances.append(hmm)\n",
    "\n",
    "    def predict(self, test_samples_list: list[FloatArray]):\n",
    "        result = [self._predict(samples) for samples in test_samples_list]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _predict(self, samples: FloatArray):\n",
    "        losses = [\n",
    "            (hmm.predict_score(samples)[1], hmm.label) for hmm in self._hmm_instances\n",
    "        ]\n",
    "\n",
    "        # TODO: Doublecheck.\n",
    "        return min(losses, key=lambda x: x[0])[1]\n",
    "\n",
    "    @classmethod\n",
    "    def from_template_file_names_and_labels(\n",
    "        cls,\n",
    "        template_file_names_for_each_label: list[list[str]],\n",
    "        labels: list[int],\n",
    "        n_states=5,\n",
    "        n_gaussians=4,\n",
    "    ):\n",
    "        assert len(template_file_names_for_each_label) == len(labels)\n",
    "        hmm_instances = []\n",
    "        for template_file_names, label in zip(\n",
    "            template_file_names_for_each_label, labels\n",
    "        ):\n",
    "            debug(f\"Calculating single HMM for number {label}.\")\n",
    "            hmm_single = single_hmm_w_template_file_names(\n",
    "                label, template_file_names, n_states, n_gaussians\n",
    "            )\n",
    "            hmm_instances.append(hmm_single)\n",
    "        return cls(\n",
    "            n_states=n_states,\n",
    "            n_gaussians=n_gaussians,\n",
    "            hmm_instances=hmm_instances,\n",
    "        )\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"HMM\")\n",
    "    parser.add_argument(\n",
    "        \"-m\", \"--hard-mode\", action=\"store_true\", help=\"Use hard mode datasets.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--n-gaussians\",\n",
    "        default=4,\n",
    "        type=int,\n",
    "        help=\"Number of gaussians for each state.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    template_indexes, test_indexes = (\n",
    "        (HARD_TEMPLATE_INDEXES, HARD_TEST_INDEXES)\n",
    "        if args.hard_mode\n",
    "        else (TEMPLATE_INDEXES, TEST_INDEXES)\n",
    "    )\n",
    "\n",
    "    template_files = [\n",
    "        [f\"recordings/{number}{i}.wav\" for i in template_indexes] for number in NUMBERS\n",
    "    ]\n",
    "    test_mfcc_s = [\n",
    "        [boosted_mfcc_from_file(f\"recordings/{number}{i}.wav\") for i in test_indexes]\n",
    "        for number in NUMBERS\n",
    "    ]\n",
    "\n",
    "    hmm = HMM.from_template_file_names_and_labels(\n",
    "        template_files, list(range(11)), n_states=5, n_gaussians=args.n_gaussians\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    for i, _ in enumerate(test_mfcc_s[0:11]):\n",
    "        print(f\"calculating probabilities for number {i}\")\n",
    "        result.append(hmm.predict(_))\n",
    "\n",
    "    print(f\"prediction: {result}\")\n",
    "    target = [[i] * 5 for i in range(11)]\n",
    "    accuracy = [\n",
    "        sum(1 for elem1, elem2 in zip(r, t) if elem1 == elem2) / len(r)\n",
    "        for r, t in zip(result, target)\n",
    "    ]\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "main() if __name__ == \"__main__\" else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
