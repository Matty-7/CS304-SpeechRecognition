{"cells":[{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5\n"]}],"source":["from typing import Dict, Optional, List\n","import numpy as np\n","\n","class HMMState:\n","    def __init__(self, mean: List[np.ndarray], covariance: List[np.ndarray], transition: Dict[\"HMMState\", float], label: Optional[int] = None, parent: Optional[\"HMMState\"] = None):\n","        self.mean = mean\n","        \"\"\"n_gaussians of mean vectors.\"\"\"\n","        self.covariance = covariance\n","        \"\"\"n_gaussians of diagonal of covariance matrix.\"\"\"\n","        self.transition = transition\n","        \"\"\"Transition probability to other HMMState instances.\"\"\"\n","        self.label = label\n","        \"\"\"The digit associated with the state. `None` if the state is the first state.\"\"\"\n","        self.parent = parent\n","        \"\"\"The state is the first state if the `parent` is `None`.\"\"\"\n","\n","    @classmethod\n","    def root(cls):\n","        \"\"\"Creates a root HMMState with default parameters.\"\"\"\n","        return cls(mean=[], covariance=[], transition={}, label=None)\n","\n","    def __hash__(self) -> int:\n","        \"\"\"Enables HMMState instances to be used as dictionary keys or in sets.\"\"\"\n","        return id(self)\n","\n","    def add_transition(self, state: \"HMMState\", probability: float):\n","        \"\"\"Adds or updates a transition probability to another state.\"\"\"\n","        self.transition[state] = probability\n","\n","    def get_transition_prob(self, state: \"HMMState\") -> float:\n","        \"\"\"Retrieves the transition probability to another state, if defined.\"\"\"\n","        return self.transition.get(state, 0.0)\n","    \n","    def get_emission_prob(self, observation: np.ndarray) -> float:\n","        \"\"\"Calculate the emission probability of an observation for this state,\n","        considering the state might represent multiple Gaussians.\"\"\"\n","        total_prob = 0.0\n","        n_gaussians = len(self.mean)\n","        \n","        for i in range(n_gaussians):\n","            mean = self.mean[i]\n","            covariance = self.covariance[i]\n","            k = mean.shape[0]\n","            covariance_det = np.prod(covariance)\n","            covariance_inv = 1 / covariance\n","            diff = observation - mean\n","            exponent = -0.5 * np.sum((diff ** 2) * covariance_inv)\n","            coefficient = 1 / np.sqrt((2 * np.pi) ** k * covariance_det)\n","            total_prob += coefficient * np.exp(exponent)\n","        \n","        # Assuming equal weight for each Gaussian component\n","        return total_prob / n_gaussians if n_gaussians > 0 else 0\n","\n","# Example of usage\n","if __name__ == \"__main__\":\n","    # Creating root state\n","    root_state = HMMState.root()\n","    \n","    # Creating another state with example data\n","    mean_example = [np.array([0.0, 1.0])]\n","    covariance_example = [np.array([1.0, 1.0])]\n","    state_example = HMMState(mean=mean_example, covariance=covariance_example, transition={}, label=1)\n","    \n","    # Adding a transition from root to example state\n","    root_state.add_transition(state_example, 0.5)\n","\n","    print(root_state.get_transition_prob(state_example))  # Example of getting a transition probability\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["from typing import List, Tuple, Dict\n","import numpy as np\n","from scipy.stats import multivariate_normal\n","\n","class HMM:\n","    def __init__(self):\n","        self.states: List[HMMState] = []\n","        self.observations: List[np.ndarray] = []\n","        self.state_index: Dict[HMMState, int] = {}\n","\n","    def add_state(self, state: HMMState):\n","        \"\"\"Adds a state to the HMM.\"\"\"\n","        self.states.append(state)\n","        self.state_index[state] = len(self.states) - 1\n","\n","    def set_observations(self, observations: List[np.ndarray]):\n","        \"\"\"Sets the sequence of observations for the HMM.\"\"\"\n","        self.observations = observations\n","\n","    def viterbi(self, observations):\n","        \"\"\"\n","        Viterbi Algorithm to find the most probable state sequence.\n","        Args:\n","            observations (List[np.ndarray]): A list of observation vectors.\n","        Returns:\n","            Tuple[List[int], float]: The most likely state sequence and its probability.\n","        \"\"\"\n","        n_states = len(self.states)\n","        n_observations = len(observations)\n","        \n","        # Initialize matrices\n","        dp = np.zeros((n_states, n_observations))  # Probability matrix\n","        backpointer = np.zeros((n_states, n_observations), dtype=int)  # Backpointer matrix\n","        \n","        # Initial probabilities\n","        for s in range(n_states):\n","            dp[s, 0] = self.states[s].get_emission_prob(observations[0]) * (1.0 / n_states)\n","        \n","        # Viterbi algorithm\n","        for t in range(1, n_observations):\n","            for s in range(n_states):\n","                (prob, state) = max(\n","                    (dp[k, t - 1] * self.states[k].get_transition_prob(self.states[s]) * self.states[s].get_emission_prob(observations[t]), k)\n","                    for k in range(n_states)\n","                )\n","                dp[s, t] = prob\n","                backpointer[s, t] = state\n","        \n","        # Reconstruct the state sequence\n","        last_state = np.argmax(dp[:, -1])\n","        path = [last_state]\n","        for t in range(n_observations - 1, 0, -1):\n","            last_state = backpointer[last_state, t]\n","            path.insert(0, last_state)\n","        \n","        # Convert state indexes to labels\n","        best_path = [self.states[i].label for i in path]\n","        max_prob = np.max(dp[:, -1])\n","        \n","        return best_path, max_prob\n","    \n","    def train(self, sequences, n_iterations=100, convergence_tol=1e-6):\n","        \"\"\"\n","        Train the HMM using the Expectation-Maximization algorithm.\n","        \n","        Args:\n","            sequences (List[List[np.ndarray]]): List of all observation sequences.\n","            n_iterations (int): Number of iterations to run the EM algorithm.\n","            convergence_tol (float): The convergence tolerance. Training stops when the change in log-likelihood is less than this value.\n","        \"\"\"\n","        previous_log_likelihood = None\n","        \n","        for iteration in range(n_iterations):\n","            # E Step\n","            all_alphas = [self._forward(seq) for seq in sequences]\n","            all_betas = [self._backward(seq) for seq in sequences]\n","            \n","            # Compute log-likelihood\n","            log_likelihood = sum(\n","                np.log(np.sum(alphas[-1])) for alphas in all_alphas\n","            )\n","            \n","            # Check for convergence\n","            if previous_log_likelihood is not None and abs(log_likelihood - previous_log_likelihood) < convergence_tol:\n","                print(f\"Model converged after {iteration} iterations.\")\n","                break\n","            previous_log_likelihood = log_likelihood\n","            \n","            # M Step\n","            self._update_states(sequences, all_alphas, all_betas)\n","            self._update_transitions(sequences, all_alphas, all_betas)\n","            \n","            # Optionally print the log-likelihood every few iterations to monitor the training progress\n","            if iteration % 10 == 0:\n","                print(f\"Iteration {iteration}: Log Likelihood = {log_likelihood}\")\n","        \n","        print(\"Training complete.\")\n","\n","    def _forward(self, obs_seq):\n","        \"\"\"\n","        Forward algorithm for calculating the probability of the observation sequence.\n","\n","        Args:\n","            obs_seq (List[np.ndarray]): Observation sequence.\n","\n","        Returns:\n","            np.ndarray: Matrix of probabilities (states x observations).\n","        \"\"\"\n","        n_states = len(self.states)\n","        n_observations = len(obs_seq)\n","        alpha = np.zeros((n_states, n_observations))\n","\n","        # Initialization\n","        for s in range(n_states):\n","            alpha[s, 0] = self.states[s].get_emission_prob(obs_seq[0]) * (1.0 / n_states)\n","\n","        # Induction\n","        for t in range(1, n_observations):\n","            for s in range(n_states):\n","                alpha[s, t] = self.states[s].get_emission_prob(obs_seq[t]) * sum(\n","                    alpha[prev_s, t - 1] * self.states[prev_s].get_transition_prob(self.states[s])\n","                    for prev_s in range(n_states)\n","                )\n","        \n","        return alpha\n","\n","    def _backward(self, obs_seq):\n","        \"\"\"\n","        Backward algorithm for calculating the probability of the future observations given current state.\n","\n","        Args:\n","            obs_seq (List[np.ndarray]): Observation sequence.\n","\n","        Returns:\n","            np.ndarray: Matrix of probabilities (states x observations).\n","        \"\"\"\n","        n_states = len(self.states)\n","        n_observations = len(obs_seq)\n","        beta = np.zeros((n_states, n_observations))\n","\n","        # Initialization\n","        beta[:, n_observations - 1] = 1  # Set all to 1 for the final probabilities\n","\n","        # Induction\n","        for t in range(n_observations - 2, -1, -1):\n","            for s in range(n_states):\n","                beta[s, t] = sum(\n","                    self.states[s].get_transition_prob(self.states[next_s]) *\n","                    self.states[next_s].get_emission_prob(obs_seq[t + 1]) * beta[next_s, t + 1]\n","                    for next_s in range(n_states)\n","                )\n","        \n","        return beta\n","\n","    def _update_states(self, sequences, all_alphas, all_betas):\n","        \"\"\"\n","        Update the emission probabilities (means and covariances) for each state.\n","        \n","        Args:\n","            sequences (List[List[np.ndarray]]): List of all observation sequences.\n","            all_alphas (List[np.ndarray]): List of alpha matrices from the forward algorithm.\n","            all_betas (List[np.ndarray]): List of beta matrices from the backward algorithm.\n","        \"\"\"\n","        for s in range(len(self.states)):\n","            # Accumulators for means and variances\n","            weighted_sum = 0\n","            weighted_square_sum = 0\n","            normalizer = 0\n","\n","            for seq_idx, obs_seq in enumerate(sequences):\n","                alphas = all_alphas[seq_idx]\n","                betas = all_betas[seq_idx]\n","                for t in range(len(obs_seq)):\n","                    # Calculate the weight for this observation at time t\n","                    weight = alphas[s, t] * betas[s, t]\n","                    # Update the accumulators\n","                    weighted_sum += weight * obs_seq[t]\n","                    weighted_square_sum += weight * np.outer(obs_seq[t], obs_seq[t])\n","                    normalizer += weight\n","\n","            # Update the means and variances for the state\n","            if normalizer > 0:\n","                new_mean = weighted_sum / normalizer\n","                new_covariance = weighted_square_sum / normalizer - np.outer(new_mean, new_mean)\n","                self.states[s].mean = [new_mean]  # Assuming a single Gaussian for simplicity\n","                self.states[s].covariance = [np.diag(new_covariance)]  # Assuming diagonal covariance for simplicity\n","\n","    def _update_transitions(self, sequences, all_alphas, all_betas):\n","        \"\"\"\n","        Update the transition probabilities between states.\n","        \n","        Args:\n","            sequences (List[List[np.ndarray]]): List of all observation sequences.\n","            all_alphas (List[np.ndarray]): List of alpha matrices from the forward algorithm.\n","            all_betas (List[np.ndarray]): List of beta matrices from the backward algorithm.\n","        \"\"\"\n","        for s in range(len(self.states)):\n","            for next_s in range(len(self.states)):\n","                numerator = 0\n","                denominator = 0\n","\n","                for seq_idx, obs_seq in enumerate(sequences):\n","                    alphas = all_alphas[seq_idx]\n","                    betas = all_betas[seq_idx]\n","                    for t in range(len(obs_seq) - 1):\n","                        numerator += (alphas[s, t] *\n","                                    self.states[s].get_transition_prob(self.states[next_s]) *\n","                                    self.states[next_s].get_emission_prob(obs_seq[t + 1]) *\n","                                    betas[next_s, t + 1])\n","\n","                        denominator += alphas[s, t] * betas[s, t]\n","\n","                # Update the transition probability from state s to state next_s\n","                if denominator > 0:\n","                    self.states[s].transition[self.states[next_s]] = numerator / denominator\n","\n","    \n","    def decode(self, sequence):\n","        \"\"\"\n","        Decode a sequence of observations and return the most probable state sequence using the Viterbi algorithm.\n","        Args:\n","            sequence (List[np.ndarray]): An observation sequence.\n","        Returns:\n","            List[int]: The most likely state sequence.\n","        \"\"\"\n","        return self.viterbi(sequence)[0]\n","\n","    def evaluate(self, sequences, labels):\n","        \"\"\"\n","        Evaluate the HMM on a test set.\n","        Args:\n","            sequences (List[List[np.ndarray]]): A list of observation sequences.\n","            labels (List[List[int]]): The true state sequences for each observation sequence.\n","        Returns:\n","            float, float: The sentence accuracy and the word accuracy.\n","        \"\"\"\n","        correct_sentences = 0\n","        correct_words = 0\n","        total_words = 0\n","\n","        for obs_seq, true_states in zip(sequences, labels):\n","            predicted_states = self.decode(obs_seq)\n","\n","            if predicted_states == true_states:\n","                correct_sentences += 1\n","\n","            correct_words += sum(p == t for p, t in zip(predicted_states, true_states))\n","            total_words += len(true_states)\n","\n","        sentence_accuracy = correct_sentences / len(sequences)\n","        word_accuracy = correct_words / total_words\n","\n","        return sentence_accuracy, word_accuracy\n","\n","\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["digit_states = {i: HMMState.root() for i in range(10)}\n","\n","for i in range(10):\n","    for j in range(10):\n","        if i != j: \n","            digit_states[i].add_transition(digit_states[j], 0.1)\n","\n","silence_state = HMMState.root()\n","for state in digit_states.values():\n","    state.add_transition(silence_state, 0.05) \n","    silence_state.add_transition(state, 0.05)\n","\n","hmm_model = HMM()\n","for state in digit_states.values():\n","    hmm_model.add_state(state)\n","hmm_model.add_state(silence_state)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":2}
