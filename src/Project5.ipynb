{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import math\n","\n","class HMMState:\n","    \"\"\"\n","    Represents a state in a Hidden Markov Model with Gaussian emissions.\n","    \n","    Attributes:\n","        mean (np.ndarray): Mean vectors of Gaussian emissions.\n","        covariance (np.ndarray): Covariance matrices (diagonal) of Gaussian emissions.\n","        label (int, optional): Associated digit with the state. None if it's an initial state.\n","        parent (HMMState, optional): Parent state. None if it's an initial state.\n","    \"\"\"\n","    def __init__(self, mean: np.ndarray, covariance: np.ndarray, label: int = None, parent: \"HMMState\" = None):\n","        \"\"\"\n","        Initializes the HMMState instance.\n","        \n","        Parameters:\n","            mean (np.ndarray): Mean vectors of Gaussian emissions.\n","            covariance (np.ndarray): Covariance matrices (diagonal) of Gaussian emissions.\n","            label (int, optional): Associated digit with the state.\n","            parent (HMMState, optional): Parent state.\n","        \"\"\"\n","        self.mean = mean\n","        self.covariance = covariance\n","        self.label = label\n","        self.parent = parent\n","    \n","    def __hash__(self):\n","        \"\"\"\n","        Returns a hash value for the state based on its label.\n","        \"\"\"\n","        return self.label\n","    \n","    def log_multivariate_gaussian_pdf_diag_cov(self, x: np.ndarray, epsilon: float = 1e-9) -> float:\n","        \"\"\"\n","        Calculates the log PDF of a multivariate Gaussian with diagonal covariance.\n","        \n","        Parameters:\n","            x (np.ndarray): The input vector.\n","            epsilon (float): Small value added to the diagonal of the covariance matrix for numerical stability.\n","            \n","        Returns:\n","            float: The log probability density function value.\n","        \"\"\"\n","        cov_safe = self.covariance + epsilon * np.eye(x.shape[0])\n","        log_det_cov = np.log(np.linalg.det(cov_safe))\n","        inv_cov = np.linalg.inv(cov_safe)\n","        const_term = -0.5 * x.shape[0] * np.log(2 * np.pi)\n","        diff = x - self.mean\n","        quadratic_term = -0.5 * np.dot(diff.T, np.dot(inv_cov, diff))\n","    \n","        return const_term - 0.5 * log_det_cov + quadratic_term\n","        \n","    def get_log_emission_prob(self, observation: np.ndarray) -> float:\n","        \"\"\"\n","        Calculates the log emission probability of an observation considering multiple Gaussian components.\n","        \n","        Parameters:\n","            observation (np.ndarray): The observed data vector.\n","            \n","        Returns:\n","            float: The log emission probability.\n","        \"\"\"\n","        if not self.mean.size or not self.covariance.size:\n","            return -np.inf # Return negative infinity if this state does not emit any observations.\n","\n","        log_probs = [\n","            self.log_multivariate_gaussian_pdf_diag_cov(observation)\n","            for mean, cov in zip(np.atleast_2d(self.mean), np.atleast_3d(self.covariance))\n","        ]\n","    \n","        max_log_prob = max(log_probs)\n","        log_sum = np.log(np.sum(np.exp(log_probs - max_log_prob))) + max_log_prob\n","        \n","        return log_sum - np.log(len(self.mean))\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-84.65269529464472\n"]}],"source":["mean = [1, 2, 3]\n","covar = [[1, 0, 0], [0, 2, 0], [0, 0, 3]]\n","\n","state = HMMState(mean, covar)\n","\n","observation = np.array([1, 20, 3])\n","log_pdf = state.log_multivariate_gaussian_pdf_diag_cov(observation)\n","\n","print(log_pdf)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","from typing import List, Dict\n","\n","def hmm_load_features(data_dir: str) -> list:\n","    \"\"\"\n","    Loads feature data from .npy files within a given directory, each file representing a sample.\n","    \n","    Parameters:\n","        data_dir (str): The path to the directory containing the .npy files.\n","        \n","    Returns:\n","        list: A list of dictionaries, where each dictionary contains 'label' as an integer and 'features' as a numpy array.\n","    \"\"\"\n","    samples = []\n","    try:\n","        for file_name in os.listdir(data_dir):\n","            if file_name.endswith('.npy'):\n","                parts = file_name.split('-')\n","                if len(parts) == 2:\n","                    label = int(parts[0])\n","                    features_path = os.path.join(data_dir, file_name)\n","                    features = np.load(features_path)\n","                    sample = {'label': label, 'features': features}\n","                    samples.append(sample)\n","    except Exception as e:\n","        print(f\"Error loading features: {e}\")\n","    return samples\n","\n","def filter_samples_by_label(samples: List[Dict], label: int) -> List[np.ndarray]:\n","    \"\"\"\n","    Filters the given list of sample dictionaries to include only those with a specific label.\n","    \n","    Parameters:\n","        samples (List[Dict]): A list of dictionaries, where each dictionary contains 'label' as an integer and 'features' as a numpy array.\n","        label (int): The label by which to filter the samples.\n","        \n","    Returns:\n","        List[np.ndarray]: A list of numpy arrays containing the features of samples that match the specified label.\n","    \"\"\"\n","    return [sample[\"features\"] for sample in samples if sample['label'] == label]\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from typing import List, Dict\n","import numpy as np\n","\n","class HMM:\n","    \"\"\"\n","    A Hidden Markov Model (HMM) with Gaussian emissions for sequence modeling.\n","\n","    This class represents a Hidden Markov Model designed for analyzing sequences of observations.\n","    It uses Gaussian distributions to model the emissions from each state, allowing for continuous observation spaces.\n","\n","    Attributes:\n","        states (List[HMMState]): The states of the HMM.\n","        transitions (np.ndarray): Transition probability matrix between states.\n","        observations (List[np.ndarray]): List of observed sequences.\n","        state_index (Dict[HMMState, int]): Mapping of states to their indices in the transition matrix.\n","        initial_probabilities (List[float]): Probability of starting in each state.\n","    \"\"\"\n","    def __init__(self, label, training_folder_path='../training'):\n","        \"\"\"\n","        Initializes the HMM with a specific label and loads training data from a specified folder path.\n","        Args:\n","            label (str): The label associated with this HMM.\n","            training_folder_path (str, optional): The path to the folder containing the training data. Defaults to '../training'.\n","        \"\"\"\n","        self.states: List[HMMState] = []\n","        data = hmm_load_features(training_folder_path)\n","        sequences = [sample['features'] for sample in data]\n","    \n","        templates_for_label = filter_samples_by_label(data, label)\n","        self.templates = templates_for_label\n","        self.num_states = self.get_num_state()\n","        self.observations: List[np.ndarray] = []\n","        self.transitions: np.ndarray = np.zeros((len(self.states), len(self.states)))\n","        self.state_index: Dict[HMMState, int] = {}\n","        self.initial_probabilities: List[float] = []  # Probability of starting in each state\n","        \n","    def calculate_mean_and_covariance(self, vectors):\n","        \"\"\"\n","        Calculates the mean vector and covariance matrix for a given list of vectors.\n","\n","        Args:\n","            vectors (List[np.ndarray]): A list of observation vectors.\n","\n","        Returns:\n","            tuple: A tuple containing the mean vector and covariance matrix.\n","        \"\"\"\n","        vectors_np = np.array(vectors)\n","        mean_vector = np.mean(vectors_np, axis=0)\n","        covariance_matrix = np.cov(vectors_np.T)\n","        return mean_vector, covariance_matrix\n","    \n","    def normalize_sequence(self, seq):\n","        \"\"\"\n","        Normalizes a sequence by maintaining increasing trends and filtering out short-term decreases.\n","\n","        Args:\n","            seq (List[float]): The sequence to normalize.\n","\n","        Returns:\n","            List[float]: The normalized sequence.\n","        \"\"\"\n","        if not seq:\n","            return seq  # Return empty list if input is empty\n","\n","        normalized_seq = [seq[0]]  # Start with the first element\n","\n","        for i in range(1, len(seq)):\n","            current = seq[i]\n","            previous = normalized_seq[-1]\n","            if current >= previous:\n","                normalized_seq.append(current)\n","            else:\n","                if i + 1 < len(seq) and seq[i + 1] >= current:\n","                    normalized_seq.append(current)\n","        return normalized_seq\n","    \n","    def print_status(self):\n","        \"\"\"\n","        Prints a comprehensive status report of the HMM, including the number of states, observation details,\n","        the transition matrix, state index mapping, and initial probabilities.\n","        \"\"\"\n","        print(\"HMM Status Report\")\n","        print(\"=================\")\n","        print(f\"Number of States: {len(self.states)}\")\n","        \n","        # Printing state index mapping\n","        print(f\"State Index Map: {len(self.state_index)} entries\")\n","        for state, index in self.state_index.items():\n","            print(f\"  State {state} -> Index {index}\")\n","        \n","        # Optionally, print details about each state\n","        for i, state in enumerate(self.states):\n","            print(f\"  State {i}: Mean {state.mean}, Covariance shape {state.covariance.shape}\")\n","        \n","        print(f\"Number of Observations: {len(self.observations)}\")\n","        for i, obs in enumerate(self.observations):\n","            print(f\"  Observation {i}: Shape {obs.shape}\")\n","        \n","        print(f\"Transition Matrix: {len(self.transitions)}x{len(self.transitions[0])}\" if self.transitions else \"Not defined\")\n","        for i, row in enumerate(self.transitions):\n","            print(f\"  Transition from State {i}: {row}\")\n","        \n","        print(f\"Initial Probabilities: {self.initial_probabilities}\")\n","\n","    def add_state(self, state: HMMState):\n","        \"\"\"\n","        Adds a new state to the HMM model, updating the transition matrix and state index accordingly.\n","\n","        Args:\n","            state (HMMState): The state to be added to the HMM.\n","        \"\"\"\n","        self.states.append(state)\n","        self.state_index[state] = len(self.states) - 1 # Assign index to the new state\n","\n","        new_transitions = np.zeros((len(self.states), len(self.states)))\n","        new_transitions[:-1, :-1] = self.transitions\n","        self.transitions = new_transitions\n","\n","        self.initial_probabilities = [1.0 / len(self.states) for _ in self.states]\n","\n","    def initialize_HMM_states(self, label, training_folder_path = '../training'):\n","        \"\"\"\n","        Initializes the HMM states by loading training data, segmenting it, and clustering\n","        to calculate mean vectors and covariance matrices for each cluster.\n","\n","        This method performs an initial segmentation of the training data for a specific label into segments,\n","        clusters these segments, and then calculates the mean vector and covariance matrix for each cluster.\n","        These mean vectors and covariances are used to initialize the states of the HMM.\n","\n","        Args:\n","            label (str): The label of the digit to initialize states for.\n","            training_folder_path (str, optional): The path to the folder containing the training data. Defaults to '../training'.\n","\n","        Returns:\n","            tuple: A tuple containing two lists; the first list contains mean vectors, and the second list contains covariance matrices for each state initialized.\n","        \"\"\"\n","        data = hmm_load_features(training_folder_path)\n","        templates_for_label = filter_samples_by_label(data, label)\n","\n","        segments = self.initial_segmentation(templates_for_label,5)\n","\n","        clusters = self.get_clusters(segments)\n","\n","        mean=[]\n","        covariances = []\n","        for cluster in clusters:\n","            mean, covariance = self.calculate_mean_and_covariance(cluster)\n","            mean.append(mean)\n","            covariances.append(covariance)\n","\n","        return mean, covariances\n","    \n","    def initialize(self, label, training_folder_path = '../training', num_states = 5):\n","        \"\"\"\n","        Initializes the HMM by setting up its states with mean vectors and covariance matrices,\n","        initial probabilities, and transition probabilities.\n","\n","        This method loads training data for a specific label, performs initial segmentation and clustering,\n","        and initializes HMM states based on the clusters. It also sets up the initial probabilities and\n","        transition probabilities between states.\n","\n","        Args:\n","            label (str): The label of the digit to initialize states for.\n","            training_folder_path (str, optional): The path to the folder containing the training data. Defaults to '../training'.\n","            num_states (int, optional): The number of states for the HMM. Defaults to 5.\n","        \"\"\"\n","        data = hmm_load_features(training_folder_path)\n","        templates_for_label = filter_samples_by_label(data, label)\n","        segmented_templates = self.initial_segmentation(templates_for_label, num_states)\n","\n","        clustered_data = self.get_clusters(segmented_templates)\n","\n","        means, variances = self.initialize_HMM_states(label, training_folder_path, num_states)\n","\n","        for i in range(num_states):\n","            new_state = HMMState(means[i], variances[i], label = i)\n","            self.states.append(new_state)\n","            self.state_index[new_state] = i\n","        \n","        self.initial_probabilities = [1.0 if i == 0 else 0.0 for i in range(num_states)]\n","\n","        self.transitions = np.zeros((num_states, num_states))\n","        for i in range(num_states):\n","            if i < num_states - 1:\n","                self.transitions[i][i + 1] = len(templates_for_label)/len(clustered_data[i])\n","                self.transitions[i][i] = 1- self.transitions[i][i + 1] # Probability of staying in the same state\n","            else:\n","                self.transitions[i][i] = 1.0  # Last state only points to itself\n","\n","\n","    def set_observations(self, observations: List[np.ndarray]):\n","        \"\"\"Sets the sequence of observations for the HMM.\"\"\"\n","        self.observations = observations\n","\n","    def most_probable_sequence(self, obs_seq):\n","        \"\"\"\n","        Computes the most probable sequence of states for a given sequence of observations using the Viterbi algorithm.\n","\n","        Args:\n","            obs_seq (List[np.ndarray]): A list of observation vectors.\n","\n","        Returns:\n","            tuple: A tuple containing the maximum log probability of the most probable sequence and the sequence of states itself.\n","        \"\"\"\n","        V = [{}]  # Stores the max log probability of the most probable path to each state at each timestep\n","        path = {}  # Stores the most probable path to each state\n","\n","        for state in self.states:\n","            initial_prob = self.initial_probabilities[self.state_index[state]]\n","            log_initial_prob = math.log(initial_prob) if initial_prob > 0 else -math.inf\n","            V[0][self.state_index[state]] = log_initial_prob + state.log_multivariate_gaussian_pdf_diag_cov(obs_seq[0])\n","            path[self.state_index[state]] = [state]\n","\n","        # Dynamic programming forward pass for t > 0\n","        for t in range(1, len(obs_seq)):\n","            V.append({})\n","            newpath = {}\n","            for cur_state in self.states:\n","                max_log_prob, best_prev_state= -math.inf, None\n","\n","                for prev_state in self.states:\n","                    transition_prob = self.transitions[self.state_index[prev_state]][self.state_index[cur_state]]\n","                    log_transition_prob = math.log(transition_prob) if transition_prob > 0 else - math.inf\n","                    log_prob = V[t-1][self.state_index[prev_state]] + log_transition_prob + cur_state.log_multivariate_gaussian_pdf_diag_cov(obs_seq[t])\n","\n","                    if log_prob > max_log_prob:\n","                        max_log_prob, best_prev_state = log_prob, prev_state\n","\n","                V[t][self.state_index[cur_state]] = max_log_prob\n","                if best_prev_state is not None:  # Check to ensure there is a valid previous state\n","                    newpath[self.state_index[cur_state]] = path[self.state_index[best_prev_state]] + [cur_state]\n","\n","            path = newpath\n","\n","        # Find the final state with the highest probability\n","        max_final_log_prob = max(V[-1].values())\n","        final_state = next(state for state, prob in V[-1].items() if prob == max_final_log_prob)\n","\n","        return (max_final_log_prob, path[final_state])\n","\n","    def initial_segmentation(self, templates, num_segments):\n","        \"\"\"\n","        Segments each template into a specified number of segments, distributing the observations evenly.\n","\n","        This method divides each observation sequence (template) in the provided list into a fixed number of segments.\n","        It ensures that the observations are as evenly distributed as possible across these segments.\n","\n","        Args:\n","            templates (List[List[np.ndarray]]): A list of templates, where each template is a list of observation vectors.\n","            num_segments (int): The number of segments to divide each template into.\n","\n","        Returns:\n","            List[List[List[np.ndarray]]]: A list of segmented templates, where each template is now a list of segments,\n","                                        and each segment is a list of observation vectors.\n","        \"\"\"\n","        segmented_templates = []\n","\n","        for template in templates:\n","            # Determine the size of each segment\n","            num_observations = len(template)\n","            segment_size = num_observations // num_segments\n","            extra = num_observations % num_segments\n","\n","            segments = []\n","            start_idx = 0\n","\n","            for _ in range(num_segments):\n","                # Adjust segment size to distribute remaining observations\n","                end_idx = start_idx + segment_size + (1 if extra > 0 else 0)\n","                # Decrease extra count until it's distributed\n","                extra -= 1 if extra > 0 else 0\n","\n","                # Extract the segment and add to the list\n","                segment = template[start_idx:end_idx]\n","                segments.append(segment)\n","\n","                start_idx = end_idx\n","\n","            segmented_templates.append(segments)\n","\n","        return segmented_templates\n","    \n","    def get_clusters(self, segmented_templates, num_segments = 5):\n","        \"\"\"\n","        Clusters segments across all templates into a dictionary, where each key represents a segment index\n","        and its value is an array of all segments from all templates corresponding to that index.\n","\n","        Args:\n","            segmented_templates (List[List[List[np.ndarray]]]): A list of segmented templates.\n","            num_segments (int, optional): The expected number of segments in each template. Defaults to 5.\n","\n","        Returns:\n","            dict: A dictionary where keys are segment indices and values are arrays of segments.\n","        \"\"\"\n","        clusters = {}\n","        \n","        for i, template in enumerate(segmented_templates):\n","            for j, segment in enumerate(template):\n","                if j < num_segments:\n","                    if j not in clusters:\n","                        clusters[j] = np.array(segment, dtype=object)\n","                    else:\n","                        clusters[j] = np.concatenate((clusters[j], np.array(segment, dtype=object)))\n","        \n","        return clusters\n","    \n","    def segment_based_on_indices(self, template, indices):\n","        \"\"\"\n","        Segments a single template based on a list of indices, effectively slicing the template into segments.\n","\n","        Args:\n","            template (List[np.ndarray]): The template to be segmented.\n","            indices (List[int]): A list of indices at which the template should be segmented.\n","\n","        Returns:\n","            List[List[np.ndarray]]: A list of segmented templates, where each segment is a list of observations.\n","        \"\"\"\n","        segmented_template = []\n","\n","        if indices:\n","            segmented_template.append(template[:indices[0]])\n","\n","            for i in range(len(indices) - 1):\n","                segment = template[indices[i]:indices[i + 1]]\n","                segmented_template.append(segment)\n","\n","            segmented_template.append(template[indices[-1]:])\n","\n","        return segmented_template\n","    \n","    def get_num_state(self):\n","        \"\"\"\n","        Returns the number of states currently defined in the HMM model.\n","\n","        Returns:\n","            int: The number of states.\n","        \"\"\"\n","        return len(self.states)\n","\n","    def train_single_iteration(self):\n","        \"\"\"\n","        Performs a single iteration of training on the HMM model using the templates.\n","\n","        This method iterates through each template, computes the most probable state sequence, normalizes the sequence,\n","        and then calculates new mean and covariance values for each state based on the segmentation of the templates.\n","        It also updates the state transition probabilities based on the newly clustered data.\n","\n","        Returns:\n","            float: The average score (probability) of the most probable sequences for all templates.\n","        \"\"\"\n","        score_total=[]\n","        split_indices=[]\n","        segmented_templates=[]\n","        \n","        for template in self.templates:\n","            probability, state_sequence = self.most_probable_sequence(template)\n","            score_total.append(probability)\n","            normalized_sequence = self.normalize_sequence([self.state_index[state] for state in state_sequence])\n","\n","            indices = [i for i, _ in enumerate(normalized_sequence[:-1]) if normalized_sequence[i] != normalized_sequence[i+1]]\n","            split_indices.append(indices)\n","            segmented_template = self.segment_based_on_indices(template, indices)\n","            segmented_templates.append(segmented_template)\n","            \n","        score = np.mean(score_total)\n","\n","        clustered_data = self.get_clusters(segmented_templates)\n","        means, covariances = [], []\n","    \n","        for cluster in clustered_data.values():\n","            mean, covariance = self.calculate_mean_and_covariance(cluster)\n","            mean.append(mean)\n","            covariances.append(covariance)\n","\n","        for i, state in enumerate(self.states):\n","            state.mean = means[i]\n","            state.covariance = covariances[i]\n","        \n","        for i in range(len(self.states)):\n","            if i < len(self.states) - 1:\n","                self.transitions[i][i + 1] = len(self.templates) / len(clustered_data[i])\n","                self.transitions[i][i] = 1 - self.transitions[i][i + 1] # Probability of staying in the same state\n","            else:\n","                self.transitions[i][i] = 1.0 \n","\n","        return score\n","    \n","    def train(self, iterations=10):\n","        \"\"\"\n","        Trains the HMM model over a specified number of iterations.\n","\n","        For each iteration, it performs a single iteration of training and prints the training score.\n","\n","        Args:\n","            iterations (int, optional): The number of training iterations to perform. Defaults to 10.\n","        \"\"\"\n","        for iteration in range(iterations):\n","            score = self.train_single_iteration()\n","            print(f'HMM training for iteration {iteration}, training score: {score}')\n","\n","    def evaluate(self, sequences, labels):\n","        \"\"\"\n","        Evaluate the HMM on a test set.\n","        Args:\n","            sequences (List[List[np.ndarray]]): A list of observation sequences.\n","            labels (List[List[int]]): The true state sequences for each observation sequence.\n","        Returns:\n","            float, float: The sentence accuracy and the word accuracy.\n","        \"\"\"\n","        correct_sentences = 0\n","        correct_words = 0\n","        total_words = 0\n","\n","        for obs_seq, true_states in zip(sequences, labels):\n","            predicted_states = self.decode(obs_seq)\n","\n","            if predicted_states == true_states:\n","                correct_sentences += 1\n","\n","            correct_words += sum(p == t for p, t in zip(predicted_states, true_states))\n","            total_words += len(true_states)\n","\n","        sentence_accuracy = correct_sentences / len(sequences)\n","        word_accuracy = correct_words / total_words\n","\n","        return sentence_accuracy, word_accuracy\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import pickle\n","\n","def save_hmm(hmm, filename):\n","    \"\"\"\n","    Save a trained Hidden Markov Model (HMM) to a file using pickle.\n","\n","    Parameters:\n","    - hmm: The HMM object to save.\n","    - filename: The name of the file where the HMM should be saved.\n","    \"\"\"\n","    with open(filename, 'wb') as file:\n","        pickle.dump(hmm, file)\n","    print(f\"HMM model has been saved to '{filename}'\")\n","    \n","def load_hmm(filename):\n","    \"\"\"\n","    Load a trained Hidden Markov Model (HMM) from a file using pickle.\n","\n","    Parameters:\n","    - filename: The name of the file from which to load the HMM.\n","\n","    Returns:\n","    - The loaded HMM object.\n","    \"\"\"\n","    with open(filename, 'rb') as file:\n","        hmm = pickle.load(file)\n","    print(f\"HMM model has been loaded from '{filename}'\")\n","    return hmm"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["'\\ndef train_all_HMM():\\n    all_label=range(0,10)\\n    for i in all_label:\\n        filename=f\\'Digit {i} HMM\\'\\n        print(f\"Training {filename}\")\\n        hmm=HMM(label=i)\\n        hmm.initialize_HMM_states(label=i)\\n        hmm.initialize(label=i)\\n        hmm.train(iterations=5)\\n        save_hmm(hmm, filename)\\n        print(f\\'{filename} training finished! Moving to the next.\\')\\n        \\ntrain_all_HMM()\\n'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","def train_all_HMM():\n","    all_label=range(0,10)\n","    for i in all_label:\n","        filename=f'Digit {i} HMM'\n","        print(f\"Training {filename}\")\n","        hmm=HMM(label=i)\n","        hmm.initialize_HMM_states(label=i)\n","        hmm.initialize(label=i)\n","        hmm.train(iterations=5)\n","        save_hmm(hmm, filename)\n","        print(f'{filename} training finished! Moving to the next.')\n","        \n","train_all_HMM()\n","\"\"\"\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import math\n","\n","def load_all_hmm():\n","    \"\"\"\n","    Loads HMM models for all ten digits.\n","\n","    This function iterates through the numbers 0 to 9, loads the HMM model for each digit,\n","    and appends it to a list of models.\n","\n","    Returns:\n","        List: A list containing HMM models for digits 0 through 9.\n","    \"\"\"\n","    hmms = []\n","    for digit in range(10):\n","        hmm = load_hmm(f'Digit {digit} HMM')\n","        hmms.append(hmm)\n","    return hmms\n","\n","def recognize(hmms, data, digit):\n","    \"\"\"\n","    Recognizes the digit from given data using a list of HMM models.\n","\n","    This function calculates the probability of the given data for each digit model and\n","    identifies the digit with the highest probability as the recognized digit.\n","\n","    Args:\n","        hmms (List): A list containing HMM models for digits 0 through 9.\n","        data: The data to be recognized/classified.\n","        digit (int): The true digit value for validation.\n","\n","    Prints:\n","        The recognized digit and validation result.\n","    \"\"\"\n","    p_max = -math.inf\n","    recognized_digit = -1\n","    for i, hmm in enumerate(hmms):\n","        probability, _ = hmm.most_prabable_sequence(data)\n","        if probability > p_max:\n","            p_max = probability\n","            recognized_digit = i\n","    \n","    print(f\"The voice is recognized as {recognized_digit}, the true value is {digit}.\")\n","    if recognized_digit == digit:\n","        print(\"Congrats, you recognized the digit correctly.\")\n","    else:\n","        print(\"Oops, it seems that you are wrong.\")\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["HMM model has been loaded from 'Digit 0 HMM'\n","HMM model has been loaded from 'Digit 1 HMM'\n","HMM model has been loaded from 'Digit 2 HMM'\n","HMM model has been loaded from 'Digit 3 HMM'\n","HMM model has been loaded from 'Digit 4 HMM'\n","HMM model has been loaded from 'Digit 5 HMM'\n","HMM model has been loaded from 'Digit 6 HMM'\n","HMM model has been loaded from 'Digit 7 HMM'\n","HMM model has been loaded from 'Digit 8 HMM'\n","HMM model has been loaded from 'Digit 9 HMM'\n"]}],"source":["hmm1 = load_all_hmm()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n","The voice is recognized as 8, the true value is 8\n","Congrats, you recognized digit right\n"]}],"source":["\n","data=hmm_load_features('../training')\n","digit=8\n","templates_for_digit=filter_samples_by_label(data, digit) \n","print(len(hmm1))  \n","recognize(hmm1,templates_for_digit[1],digit)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class Language_HMM:\n","    def __init__(self,hmms):\n","        self.states: List[HMMState] = []\n","        self.hmms=hmms\n","        self.observations: List[np.ndarray] = []\n","        self.transitions: List[List[float]] = []\n","        self.state_index: Dict[HMMState, int] = {}\n","        self.initial_probabilities: List[float] = [] \n","        self.set_state_index()\n","    def get_all_states(self,hmms):\n","        null_state=HMMState(isNull=True)\n","        self.states.append(null_state)\n","        for hmm in self.hmms[2:]:\n","            for state in hmm.states:\n","                self.states.append(state)\n","        null_state=HMMState(isNull=True)\n","        self.states.append(null_state)\n","        for i in range(1,7):\n","            for hmm in self.hmms:\n","                for state in hmm.states:\n","                    self.states.append(state)\n","            null_state=HMMState(isNull=True)\n","            self.states.append(null_state)\n","    def set_state_index(self):\n","        for i in range(len(self.states)):\n","            self.state_index[self.states[i]]=i\n","    def initialize_transition(self):\n","        self.transitions= np.zeros(len(self.states), (len(self.states)))\n","        self.set_transitions()\n","    def set_transitions(self):\n","        null_states_indices=[0,41,41+51,41+51*2,41+51*3,41+51*4,41+51*5,41+51*6]\n","        idx=0\n","        for i in range(0,8):\n","            hmm=self.hmms[2+i]\n","            for j in range(5):\n","                if j!=4:\n","                    self.transitions[5*i+j][5*i+j+1]=hmm.transitions[j][j+1]\n","                    self.transitions[5*i+j][5*i+j]=hmm.transitions[j][j]\n","                else:\n","                    self.transitions[5*i+j][5*i+j]=hmm.transitions[j][j]\n","        for k in range(1,7):\n","            c=42+51*(k-1)\n","            for i in range(0,10):\n","                hmm=self.hmms[i]\n","                for j in range(5):\n","                    if j!=4:\n","                        self.transitions[5*i+j+c][5*i+j+c+1]=hmm.transitions[j][j+1]\n","                        self.transitions[5*i+j+c][5*i+j+c]=hmm.transitions[j][j]\n","                    else:\n","                        self.transitions[5*i+j+c][5*i+j+c]=hmm.transitions[j][j]\n","\n"," \n","        for i in range(len(self.states)):\n","            if i==0:\n","                for m in range(8):\n","                    self.transitions[i][i+5*m+1]=1/9\n","            elif i==1:\n","                for m in range(8):\n","                    self.transitions[i-5*m-1][i]=1/8\n","            elif i==null_states_indices[-1]:\n","                for m in range(10):\n","                    self.transitions[i-5*m-1][i]=1/10\n","            elif i==null_states_indices[3]:\n","                for m in range(10):\n","                    self.transitions[i-5*m-1][i]=1/11\n","                    self.transitions[i][i+5*m+1]=1/10\n","            else:\n","                for m in range(10):\n","                    self.transitions[i-5*m-1][i]=1/10\n","                    self.transitions[i][i+5*m+1]=1/10\n","\n","    def most_probable_sequence(self, obs_seq):\n","        V = [{}]\n","        path = {}\n","\n","        for state in self.states:\n","            initial_prob = self.initial_probabilities[self.state_index[state]]\n","            V[0][self.state_index[state]] = (math.log(initial_prob) if initial_prob > 0 else -math.inf) + state.log_multivariate_gaussian_pdf_diag_cov(obs_seq[0])\n","            path[self.state_index[state]] = [state]\n","\n","        # Run Viterbi for t > 0\n","        for t in range(1, len(obs_seq)):\n","            V.append({})\n","            newpath = {}\n","            for cur_state in self.states:\n","                max_log_prob = -math.inf  # Initialize with negative infinity for comparison\n","                best_prev_state = None  # Initialize with None to find the best previous state\n","                for prev_state in self.states:\n","                    transition_prob = self.transitions[self.state_index[prev_state]][self.state_index[cur_state]]\n","                    log_transition_prob = math.log(transition_prob) if transition_prob > 0 else -math.inf\n","                    log_prob = V[t-1][self.state_index[prev_state]] + log_transition_prob + cur_state.log_multivariate_gaussian_pdf_diag_cov(obs_seq[t])\n","                    if log_prob > max_log_prob:\n","                        max_log_prob = log_prob\n","                        best_prev_state = prev_state\n","                V[t][self.state_index[cur_state]] = max_log_prob\n","                if best_prev_state is not None:  # Check to ensure there is a valid previous state\n","                    newpath[self.state_index[cur_state]] = path[self.state_index[best_prev_state]] + [cur_state]\n","            path = newpath\n","\n","        # Find the final state with the highest probability\n","        max_final_log_prob = max(V[-1].values())\n","        final_state = [state for state, prob in V[-1].items() if prob == max_final_log_prob][0]\n","\n","        return (max_final_log_prob, path[final_state])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import librosa\n","import numpy as np\n","import os\n","\n","def compute_mfcc_features(file_path, n_mfcc=39):\n","    y, sr = librosa.load(file_path)\n","    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n","    delta_mfcc = librosa.feature.delta(mfcc)\n","    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n","    features = np.vstack([mfcc, delta_mfcc, delta2_mfcc])\n","    return features\n","\n","def process_folder(folder_path):\n","    features_dict = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith('.wav'):  # Ensure processing only wav files\n","            file_path = os.path.join(folder_path, file_name)\n","            features = compute_mfcc_features(file_path)\n","            features_dict[file_name] = features\n","    return features_dict\n","\n","# Assuming your test folder is in the current directory\n","folder_path = '../Project5/problem1'\n","features_dict = process_folder(folder_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}
