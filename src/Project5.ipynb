{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5\n"]}],"source":["from typing import Dict, Optional, List\n","import numpy as np\n","\n","class HMMState:\n","    def __init__(self, mean: List[np.ndarray], covariance: List[np.ndarray], transition: Dict[\"HMMState\", float], label: Optional[int] = None, parent: Optional[\"HMMState\"] = None):\n","        self.mean = mean\n","        \"\"\"n_gaussians of mean vectors.\"\"\"\n","        self.covariance = covariance\n","        \"\"\"n_gaussians of diagonal of covariance matrix.\"\"\"\n","        self.transition = transition\n","        \"\"\"Transition probability to other HMMState instances.\"\"\"\n","        self.label = label\n","        \"\"\"The digit associated with the state. `None` if the state is the first state.\"\"\"\n","        self.parent = parent\n","        \"\"\"The state is the first state if the `parent` is `None`.\"\"\"\n","\n","    @classmethod\n","    def root(cls):\n","        \"\"\"Creates a root HMMState with default parameters.\"\"\"\n","        return cls(mean=[], covariance=[], transition={}, label=None)\n","\n","    def __hash__(self) -> int:\n","        \"\"\"Enables HMMState instances to be used as dictionary keys or in sets.\"\"\"\n","        return id(self)\n","\n","    def add_transition(self, state: \"HMMState\", probability: float):\n","        \"\"\"Adds or updates a transition probability to another state.\"\"\"\n","        self.transition[state] = probability\n","\n","    def get_transition_prob(self, state: \"HMMState\") -> float:\n","        \"\"\"Retrieves the transition probability to another state, if defined.\"\"\"\n","        return self.transition.get(state, 0.0)\n","    \n","    def get_emission_prob(self, observation: np.ndarray) -> float:\n","        \"\"\"Calculate the emission probability of an observation for this state,\n","        considering the state might represent multiple Gaussians.\"\"\"\n","        total_prob = 0.0\n","        n_gaussians = len(self.mean)\n","        \n","        for i in range(n_gaussians):\n","            mean = self.mean[i]\n","            covariance = self.covariance[i]\n","            k = mean.shape[0]\n","            covariance_det = np.prod(covariance)\n","            covariance_inv = 1 / covariance\n","            diff = observation - mean\n","            exponent = -0.5 * np.sum((diff ** 2) * covariance_inv)\n","            coefficient = 1 / np.sqrt((2 * np.pi) ** k * covariance_det)\n","            total_prob += coefficient * np.exp(exponent)\n","        \n","        # Assuming equal weight for each Gaussian component\n","        return total_prob / n_gaussians if n_gaussians > 0 else 0\n","\n","# Example of usage\n","if __name__ == \"__main__\":\n","    # Creating root state\n","    root_state = HMMState.root()\n","    \n","    # Creating another state with example data\n","    mean_example = [np.array([0.0, 1.0])]\n","    covariance_example = [np.array([1.0, 1.0])]\n","    state_example = HMMState(mean=mean_example, covariance=covariance_example, transition={}, label=1)\n","    \n","    # Adding a transition from root to example state\n","    root_state.add_transition(state_example, 0.5)\n","\n","    print(root_state.get_transition_prob(state_example))  # Example of getting a transition probability\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0.01504398  2.16612759  1.46242275 -0.29369514 -0.36467441 -0.72936447\n"," -0.23512171 -0.68352914 -0.37624469  0.61635837 -0.24605661  0.68253881\n","  1.61070103  0.          2.58490267 -0.02764636 -1.90674222 -0.36871204\n"," -0.16015593  0.43935257 -0.35445498  0.3711728   0.99492332 -0.48697788\n","  0.52177869  0.60881164  0.          2.58490267 -0.92923506 -0.82941034\n","  1.49801127  0.05107395  0.47230517 -0.44749896  0.39624165  0.24542344\n"," -0.77641316  0.51410951  0.01046   ]\n"]}],"source":["from typing import List, Dict,Tuple\n","import numpy as np\n","import os\n","from sklearn.cluster import KMeans\n","\n","\n","class HMM:\n","    def __init__(self):\n","        self.states: List[HMMState] = []\n","        self.observations: List[np.ndarray] = []\n","        self.transitions: List[List[float]] = []\n","        self.state_index: Dict[HMMState, int] = {}\n","        self.initial_probabilities: List[float] = []  # Probability of starting in each state\n","\n","    def add_state(self, state: HMMState):\n","        \"\"\"Adds a state to the HMM.\"\"\"\n","        self.states.append(state)\n","        index = len(self.states) - 1\n","        self.state_index[state] = index\n","        # Ensure transitions matrix is updated to reflect the new state\n","        for row in self.transitions:\n","            row.append(0.0)  # Append 0.0 for new state to existing states\n","        self.transitions.append([0.0 for _ in range(len(self.states))])  # Add new state with transitions\n","\n","    def initialize(self):\n","        num_states = 5\n","        for _ in range(num_states):\n","            # Create a new state and add it\n","            new_state = HMMState()\n","            self.add_state(new_state)\n","        \n","        # Set initial probabilities (uniform distribution for simplicity)\n","        self.initial_probabilities = [1.0 / num_states for _ in range(num_states)]\n","        \n","        # Set up transitions\n","        for i in range(num_states):\n","            if i < num_states - 1:\n","                self.transitions[i][i] = 0.5  # Probability of staying in the same state\n","                self.transitions[i][i + 1] = 0.5  # Probability of moving to the next state\n","            else:\n","                self.transitions[i][i] = 1.0  # Last state only points to itself\n","\n","\n","    def set_observations(self, observations: List[np.ndarray]):\n","        \"\"\"Sets the sequence of observations for the HMM.\"\"\"\n","        self.observations = observations\n","\n","    def viterbi(self) -> Tuple[List[int], float]:\n","        \"\"\"Finds the most probable sequence of states given the observations using the Viterbi algorithm.\"\"\"\n","        num_states = len(self.states)\n","        num_observations = len(self.observations)\n","        if num_observations == 0:\n","            return [], 0.0  # No observations, return empty path and zero probability\n","\n","        # Initialize DP tables\n","        dp = np.zeros((num_states, num_observations))\n","        backpointer = np.zeros((num_states, num_observations), dtype=int)\n","\n","        # Initialization step\n","        for s in range(num_states):\n","            dp[s, 0] = self.initial_probabilities[s] * self.states[s].emission_probability(self.observations[0])\n","\n","        # Recursion step\n","        for t in range(1, num_observations):\n","            for s in range(num_states):\n","                transition_probabilities = [dp[prev_state, t-1] * self.transitions[prev_state][s] for prev_state in range(num_states)]\n","                max_transition_prob = max(transition_probabilities)\n","                dp[s, t] = max_transition_prob * self.states[s].emission_probability(self.observations[t])\n","                backpointer[s, t] = transition_probabilities.index(max_transition_prob)\n","\n","        # Termination step\n","        best_path_prob = max(dp[:, num_observations-1])\n","        best_last_state = np.argmax(dp[:, num_observations-1])\n","\n","        # Backtrack to find best path\n","        best_path = [best_last_state]\n","        for t in range(num_observations-1, 0, -1):\n","            best_last_state = backpointer[best_last_state, t]\n","            best_path.insert(0, best_last_state)\n","\n","        return best_path, best_path_prob\n","    def initial_segmentation(self, templates, num_segments):\n","    \n","        segmented_templates = []\n","\n","        for template in templates:\n","        # Determine the size of each segment\n","            num_observations = len(template)\n","            segment_size = num_observations // num_segments\n","            extra = num_observations % num_segments\n","\n","            segments = []\n","            start_idx = 0\n","\n","            for _ in range(num_segments):\n","            # Adjust segment size to distribute remaining observations\n","                end_idx = start_idx + segment_size + (1 if extra > 0 else 0)\n","            # Decrease extra count until it's distributed\n","                extra -= 1 if extra > 0 else 0\n","\n","            # Extract the segment and add to the list\n","                segment = template[start_idx:end_idx]\n","                segments.append(segment)\n","\n","                start_idx = end_idx\n","\n","            segmented_templates.append(segments)\n","\n","        return segmented_templates\n","\n","    \n","    def load_features_and_train(training_folder):\n","        # Placeholder for loading features and training HMM for each digit\n","        print(f\"Loading features from {training_folder}...\")\n","        # Here we would load the .npy files and train each digit's HMM\n","        # For now, we will just print out what would normally happen.\n","        for digit in range(10):\n","            for i in range(1, 11):  # 10 feature files per digit\n","                feature_path = os.path.join(training_folder, f\"{digit}-{i}.npy\")\n","                print(f\"Training HMM for digit {digit} with features from {feature_path}...\")\n","                # Here we would load the features using numpy.load(feature_path)\n","                # And then train the HMM for this digit using these features\n","\n","\n","    \n","    def train(self, sequences, n_iterations=100, convergence_tol=1e-6):\n","        \"\"\"\n","        Train the HMM using the Expectation-Maximization algorithm.\n","        \n","        Args:\n","            sequences (List[List[np.ndarray]]): List of all observation sequences.\n","            n_iterations (int): Number of iterations to run the EM algorithm.\n","            convergence_tol (float): The convergence tolerance. Training stops when the change in log-likelihood is less than this value.\n","        \"\"\"\n","        previous_log_likelihood = None\n","        \n","        for iteration in range(n_iterations):\n","            # E Step\n","            all_alphas = [self._forward(seq) for seq in sequences]\n","            all_betas = [self._backward(seq) for seq in sequences]\n","            \n","            # Compute log-likelihood\n","            log_likelihood = sum(\n","                np.log(np.sum(alphas[-1])) for alphas in all_alphas\n","            )\n","            \n","            # Check for convergence\n","            if previous_log_likelihood is not None and abs(log_likelihood - previous_log_likelihood) < convergence_tol:\n","                print(f\"Model converged after {iteration} iterations.\")\n","                break\n","            previous_log_likelihood = log_likelihood\n","            \n","            # M Step\n","            self._update_states(sequences, all_alphas, all_betas)\n","            self._update_transitions(sequences, all_alphas, all_betas)\n","            \n","            # Optionally print the log-likelihood every few iterations to monitor the training progress\n","            if iteration % 10 == 0:\n","                print(f\"Iteration {iteration}: Log Likelihood = {log_likelihood}\")\n","        \n","        print(\"Training complete.\")\n","\n","    def _forward(self, obs_seq):\n","        \"\"\"\n","        Forward algorithm for calculating the probability of the observation sequence.\n","\n","        Args:\n","            obs_seq (List[np.ndarray]): Observation sequence.\n","\n","        Returns:\n","            np.ndarray: Matrix of probabilities (states x observations).\n","        \"\"\"\n","        n_states = len(self.states)\n","        n_observations = len(obs_seq)\n","        alpha = np.zeros((n_states, n_observations))\n","\n","        # Initialization\n","        for s in range(n_states):\n","            alpha[s, 0] = self.states[s].get_emission_prob(obs_seq[0]) * (1.0 / n_states)\n","\n","        # Induction\n","        for t in range(1, n_observations):\n","            for s in range(n_states):\n","                alpha[s, t] = self.states[s].get_emission_prob(obs_seq[t]) * sum(\n","                    alpha[prev_s, t - 1] * self.states[prev_s].get_transition_prob(self.states[s])\n","                    for prev_s in range(n_states)\n","                )\n","        \n","        return alpha\n","\n","    def _backward(self, obs_seq):\n","        \"\"\"\n","        Backward algorithm for calculating the probability of the future observations given current state.\n","\n","        Args:\n","            obs_seq (List[np.ndarray]): Observation sequence.\n","\n","        Returns:\n","            np.ndarray: Matrix of probabilities (states x observations).\n","        \"\"\"\n","        n_states = len(self.states)\n","        n_observations = len(obs_seq)\n","        beta = np.zeros((n_states, n_observations))\n","\n","        # Initialization\n","        beta[:, n_observations - 1] = 1  # Set all to 1 for the final probabilities\n","\n","        # Induction\n","        for t in range(n_observations - 2, -1, -1):\n","            for s in range(n_states):\n","                beta[s, t] = sum(\n","                    self.states[s].get_transition_prob(self.states[next_s]) *\n","                    self.states[next_s].get_emission_prob(obs_seq[t + 1]) * beta[next_s, t + 1]\n","                    for next_s in range(n_states)\n","                )\n","        \n","        return beta\n","\n","    def _update_states(self, sequences, all_alphas, all_betas):\n","        \"\"\"\n","        Update the emission probabilities (means and covariances) for each state.\n","        \n","        Args:\n","            sequences (List[List[np.ndarray]]): List of all observation sequences.\n","            all_alphas (List[np.ndarray]): List of alpha matrices from the forward algorithm.\n","            all_betas (List[np.ndarray]): List of beta matrices from the backward algorithm.\n","        \"\"\"\n","        for s in range(len(self.states)):\n","            # Accumulators for means and variances\n","            weighted_sum = 0\n","            weighted_square_sum = 0\n","            normalizer = 0\n","\n","            for seq_idx, obs_seq in enumerate(sequences):\n","                alphas = all_alphas[seq_idx]\n","                betas = all_betas[seq_idx]\n","                for t in range(len(obs_seq)):\n","                    # Calculate the weight for this observation at time t\n","                    weight = alphas[s, t] * betas[s, t]\n","                    # Update the accumulators\n","                    weighted_sum += weight * obs_seq[t]\n","                    weighted_square_sum += weight * np.outer(obs_seq[t], obs_seq[t])\n","                    normalizer += weight\n","\n","            # Update the means and variances for the state\n","            if normalizer > 0:\n","                new_mean = weighted_sum / normalizer\n","                new_covariance = weighted_square_sum / normalizer - np.outer(new_mean, new_mean)\n","                self.states[s].mean = [new_mean]  # Assuming a single Gaussian for simplicity\n","                self.states[s].covariance = [np.diag(new_covariance)]  # Assuming diagonal covariance for simplicity\n","\n","    def _update_transitions(self, sequences, all_alphas, all_betas):\n","        \"\"\"\n","        Update the transition probabilities between states.\n","        \n","        Args:\n","            sequences (List[List[np.ndarray]]): List of all observation sequences.\n","            all_alphas (List[np.ndarray]): List of alpha matrices from the forward algorithm.\n","            all_betas (List[np.ndarray]): List of beta matrices from the backward algorithm.\n","        \"\"\"\n","        for s in range(len(self.states)):\n","            for next_s in range(len(self.states)):\n","                numerator = 0\n","                denominator = 0\n","\n","                for seq_idx, obs_seq in enumerate(sequences):\n","                    alphas = all_alphas[seq_idx]\n","                    betas = all_betas[seq_idx]\n","                    for t in range(len(obs_seq) - 1):\n","                        numerator += (alphas[s, t] *\n","                                    self.states[s].get_transition_prob(self.states[next_s]) *\n","                                    self.states[next_s].get_emission_prob(obs_seq[t + 1]) *\n","                                    betas[next_s, t + 1])\n","\n","                        denominator += alphas[s, t] * betas[s, t]\n","\n","                # Update the transition probability from state s to state next_s\n","                if denominator > 0:\n","                    self.states[s].transition[self.states[next_s]] = numerator / denominator\n","\n","    \n","    def decode(self, sequence):\n","        \"\"\"\n","        Decode a sequence of observations and return the most probable state sequence using the Viterbi algorithm.\n","        Args:\n","            sequence (List[np.ndarray]): An observation sequence.\n","        Returns:\n","            List[int]: The most likely state sequence.\n","        \"\"\"\n","        return self.viterbi(sequence)[0]\n","\n","    def evaluate(self, sequences, labels):\n","        \"\"\"\n","        Evaluate the HMM on a test set.\n","        Args:\n","            sequences (List[List[np.ndarray]]): A list of observation sequences.\n","            labels (List[List[int]]): The true state sequences for each observation sequence.\n","        Returns:\n","            float, float: The sentence accuracy and the word accuracy.\n","        \"\"\"\n","        correct_sentences = 0\n","        correct_words = 0\n","        total_words = 0\n","\n","        for obs_seq, true_states in zip(sequences, labels):\n","            predicted_states = self.decode(obs_seq)\n","\n","            if predicted_states == true_states:\n","                correct_sentences += 1\n","\n","            correct_words += sum(p == t for p, t in zip(predicted_states, true_states))\n","            total_words += len(true_states)\n","\n","        sentence_accuracy = correct_sentences / len(sequences)\n","        word_accuracy = correct_words / total_words\n","\n","        return sentence_accuracy, word_accuracy\n","def hmm_load_features(data_dir):\n","    #创建一个空列表来存储样本对象\n","    samples = []\n","\n","    #*循环读取数据并创建样本对象，每个样本对象包括特征数据和标签\n","    for file_name in os.listdir(data_dir):\n","        if file_name.endswith('.npy'):\n","            # 解析文件名，获取标签信息\n","            parts = file_name.split('-')\n","            if len(parts) == 2 and parts[1].endswith('.npy'):\n","                label = int(parts[0])\n","                \n","                # 加载特征数据\n","                features = np.load(os.path.join(data_dir, file_name))\n","\n","                # 创建样本对象并添加到列表中\n","                sample = {'label': label, 'features': features}\n","                samples.append(sample)\n","\n","    return samples\n","def filter_samples_by_label(samples, label=1):\n","    \"\"\"\n","    Filters the list of sample dictionaries to include only those with a specific label.\n","\n","    :param samples: List of dictionaries, where each dictionary contains 'label' and 'features' keys.\n","    :param label: The label to filter by (default is 1).\n","    :return: A filtered list of dictionaries.\n","    \"\"\"\n","    return [sample[\"features\"] for sample in samples if sample['label'] == label]\n","    # Assuming the training folder path is correct\n","training_folder_path = '../training'  # This path will need to be updated to the actual path\n","hmm=HMM()\n","#hmm.load_features_and_train(training_folder_path)\n","data=hmm_load_features(training_folder_path)\n","#print(data)\n","#for digit in range(10):\n","        #for i in range(1, 11):  # 10 feature files per digit\n","            #feature_path = os.path.join(training_folder_path, f\"{digit}-{i}.npy\")\n","            #print(f\"Training HMM for digit {digit} with features from {feature_path}...\")\n","i_digit_data=filter_samples_by_label(data, label=1)\n","    #print(f'the features for digit {i} is {i_thdata}')\n","#i_thdata[kth_template][n_th mfcc feature vector][39 dim-mfcc]\n","print(i_digit_data[0][1])\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["class TelephoneNumberFSM:\n","    def __init__(self):\n","        self.current_state = 'start'\n","        self.states=['start','area_1','area_2','area_3','number_1','number_2','number_3','number_4','end']\n","        # Initialize transitions with area code skip option\n","        self.transitions = {\n","            'start': {},\n","            'area_1': {},\n","            'area_2': {},\n","            'area_3': {},\n","            'number_1': {},\n","            'number_2': {},\n","            'number_3': {},\n","            'number_4': {},\n","            'end': {}\n","        }\n","        # Define valid digits for transitions\n","        self.valid_digits = [str(i) for i in range(10)]  # '0' to '9'\n","        self.first_digit_options = [str(i) for i in range(2, 10)]  # '2' to '9'\n","        # Populate transitions using loops\n","        self.populate_transitions()\n","\n","    def populate_transitions(self):\n","        # Start state transitions\n","        for digit in self.first_digit_options:\n","            self.transitions['start'][digit] = 'area_1'\n","        self.transitions['start']['skip'] = 'number_1'  # Skip to number if no area code\n","        \n","        # Area code transitions\n","        for state in ['area_1', 'area_2', 'area_3']:\n","            for digit in self.valid_digits:\n","                next_state = 'area_3' if state == 'area_2' else 'number_1' if state == 'area_3' else 'area_2'\n","                self.transitions[state][digit] = next_state\n","        \n","        # Number transitions\n","        current_state = 'number_1'\n","        for i in range(1, 5):  # number_1 to number_4\n","            for digit in self.valid_digits:\n","                next_state = 'end' if i == 4 else f'number_{i+1}'\n","                self.transitions[f'number_{i}'][digit] = next_state\n","\n","    def transition(self, input):\n","        if input in self.transitions[self.current_state]:\n","            self.current_state = self.transitions[self.current_state][input]\n","        else:\n","            raise ValueError(f\"Invalid transition from {self.current_state} with input {input}\")\n","\n","    def is_valid_number(self):\n","        return self.current_state == 'end'\n","\n","# Example usage\n","fsm = TelephoneNumberFSM()\n","try:\n","    for digit in \"2851234\":  # Example number without area code\n","        fsm.transition(digit)\n","    print(fsm.is_valid_number())  # Check if it's a valid telephone number\n","except ValueError as e:\n","    print(e)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["digit_states = {i: HMMState.root() for i in range(10)}\n","\n","for i in range(10):\n","    for j in range(10):\n","        if i != j: \n","            digit_states[i].add_transition(digit_states[j], 0.1)\n","\n","silence_state = HMMState.root()\n","for state in digit_states.values():\n","    state.add_transition(silence_state, 0.05) \n","    silence_state.add_transition(state, 0.05)\n","\n","hmm_model = HMM()\n","for state in digit_states.values():\n","    hmm_model.add_state(state)\n","hmm_model.add_state(silence_state)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":2}
