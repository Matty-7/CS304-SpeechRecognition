{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GMMHMM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(model, filepath, save_name):\n",
    "    \"\"\"\n",
    "    Save a trained model using Pickle.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model object to be saved.\n",
    "        filepath: The directory path where the model file will be saved.\n",
    "        save_name: The name to be used for the saved model file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pkl_filename = filepath + save_name + '.pkl'  # Define the pickle file path\n",
    "\n",
    "    # Open the file to save as a pkl file\n",
    "    with open(pkl_filename, 'wb') as model_pkl:\n",
    "        pickle.dump(model, model_pkl)  # Dump the model using Pickle\n",
    "\n",
    "    # No need to explicitly close the file; the 'with' statement handles it automatically\n",
    "\n",
    "def load_pickle(filepath, save_name):\n",
    "    \"\"\"\n",
    "    Load a saved model using Pickle.\n",
    "\n",
    "    Args:\n",
    "        filepath: The directory path where the saved model file is located.\n",
    "        save_name: The name of the saved model file.\n",
    "\n",
    "    Returns:\n",
    "        The loaded model object.\n",
    "    \"\"\"\n",
    "    classification_pkl_filename = filepath + \"/\" + save_name + '.pkl'  # Define the path to the saved model file\n",
    "\n",
    "    with open(classification_pkl_filename, 'rb') as classification_model_pkl:\n",
    "        classification_model = pickle.load(classification_model_pkl)  # Load the model from the pickle file\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_digit_GMMHMM(filepath,filenames):\n",
    "    GMMHMMs={}\n",
    "    for digit in filenames:\n",
    "        print(\"Loading the digit {} GMMHMM\".format(digit))\n",
    "        current_digit_GMMHMM=load_pickle(filepath,str(digit))\n",
    "        GMMHMMs[str(digit)]=current_digit_GMMHMM\n",
    "    return GMMHMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the digit 0 GMMHMM\n",
      "Loading the digit 1 GMMHMM\n",
      "Loading the digit 2 GMMHMM\n",
      "Loading the digit 3 GMMHMM\n",
      "Loading the digit 4 GMMHMM\n",
      "Loading the digit 5 GMMHMM\n",
      "Loading the digit 6 GMMHMM\n",
      "Loading the digit 7 GMMHMM\n",
      "Loading the digit 8 GMMHMM\n",
      "Loading the digit 9 GMMHMM\n"
     ]
    }
   ],
   "source": [
    "filepath=\"models/\"\n",
    "filenames=[0,1,2,3,4,5,6,7,8,9]\n",
    "GMMHMMS=load_all_digit_GMMHMM(filepath,filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexNode:\n",
    "    def __init__(self, val,word):\n",
    "        self.val = val\n",
    "        self.word= word\n",
    "        self.children = []\n",
    "        # set the property so that we can differentiate the start node, normal(between) node and end of word node\n",
    "        # 0: normal node\n",
    "        # 1: start node\n",
    "        # 2: end-of-word node\n",
    "        self.property = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildLextree:\n",
    "    def __init__(self, dic):\n",
    "        \n",
    "        self.dic2words(dic)\n",
    "        zeros=np.zeros([39])\n",
    "        ones=np.zeros([39])+1\n",
    "        \n",
    "        #create a fine GMM \n",
    "        fine_GMM=mixInfo()\n",
    "        fine_GMM.Gaussian_mean.append(zeros)\n",
    "        #fine_GMM.Gaussian_mean.append(zeros)\n",
    "        fine_GMM.Gaussian_var.append(ones)\n",
    "        #fine_GMM.Gaussian_var.append(ones)\n",
    "        fine_GMM.Gaussian_weight=[1]\n",
    "        #translate from list to np array\n",
    "        fine_GMM.Gaussian_mean=np.array(fine_GMM.Gaussian_mean)\n",
    "        fine_GMM.Gaussian_var=np.array(fine_GMM.Gaussian_var)\n",
    "        fine_GMM.Num_of_Gaussian = 1\n",
    "        self.tree=LexNode(fine_GMM,\"*\")\n",
    "        # dummy symbol for the root of the tree\n",
    "        self.tree.property = 1\n",
    "        \n",
    "        print(\"There are {} words in this dictionary\".format(len(self.words)))\n",
    "        \n",
    "    def dic2words(self,dic):\n",
    "        self.words=[]\n",
    "        self.keys=list(dic.keys())\n",
    "        self.transition_cost={}\n",
    "        for key in self.keys:\n",
    "            self.words.append(dic[key])\n",
    "            self.transition_cost[key]=dic[key].hmm.transition_cost\n",
    "        \n",
    "    def append_lex_node(self,parent, child):\n",
    "        #This function just append the child node to the paretn node\n",
    "        #It would check whether the parent is a LexNode!\n",
    "        assert type(parent) is LexNode and type(child) is LexNode\n",
    "        parent.children.append(child)\n",
    "    \n",
    "    def build_lextree(self):\n",
    "        #this is the function to build the lextree from the self.words and root node \"*\"\n",
    "        for i in range(len(self.words)):\n",
    "            word=self.words[i]\n",
    "            key=self.keys[i]\n",
    "            previous_node=LexNode(word.hmm.mix[0],key)\n",
    "            self.tree.children.append(previous_node)\n",
    "            for j in range(1,word.hmm.N):\n",
    "                current_node=LexNode(word.hmm.mix[j],key)\n",
    "                previous_node.children.append(current_node)\n",
    "                previous_node=current_node\n",
    "            previous_node.children.append(self.tree)\n",
    "            previous_node.property=2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 words in this dictionary\n"
     ]
    }
   ],
   "source": [
    "buildlextree=BuildLextree(GMMHMMS)\n",
    "buildlextree.build_lextree()\n",
    "lextree=buildlextree.tree\n",
    "transition_cost=buildlextree.transition_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinousSpeechRecognition():\n",
    "    def __init__(self):\n",
    "        self.lextree=None\n",
    "        self.dist_fun=None\n",
    "        \n",
    "    def fit(self,lextree,transition_cost):\n",
    "        self.lextree=lextree\n",
    "        assert type(self.lextree) is LexNode\n",
    "        self.nodes = []\n",
    "        self.get_nodes(self.lextree)\n",
    "        self.initial_nodes_idx=[]\n",
    "        for i in self.initial_nodes:\n",
    "            self.initial_nodes_idx.append(self.nodes.index(i))\n",
    "        # get self.transitions\n",
    "        self.transition_cost=transition_cost\n",
    "        self.get_parent = {}\n",
    "        self.get_children={}\n",
    "        \n",
    "        n_nodes = len(self.nodes)\n",
    "        self.word_ends = []\n",
    "        # record the end idx of each words, therefore, at the end of the vertibe , we can get the costs of each word\n",
    "        for i in range(n_nodes):\n",
    "            n = self.nodes[i]\n",
    "            if n.property == 2:\n",
    "                self.word_ends.append(i)\n",
    "            self.get_children[i]=[]\n",
    "            # add transition if there is any. to get the parent node of current node\n",
    "            if len(n.children) > 0:\n",
    "                for child in n.children:\n",
    "                    self.get_children[i].append(self.nodes.index(child))\n",
    "                    self.get_parent[self.nodes.index(child)] = i\n",
    "                \n",
    "    def get_nodes(self, lexnode):\n",
    "        self.nodes=[]\n",
    "        self.states=[]\n",
    "        self.initial_nodes=[]\n",
    "        words=lexnode.children\n",
    "        self.states.append(0)\n",
    "        self.nodes.append(lexnode)\n",
    "        for word in words:\n",
    "            state=0\n",
    "            current_GMM=word\n",
    "            self.initial_nodes.append(current_GMM)\n",
    "            while current_GMM.property!=2:\n",
    "                state+=1\n",
    "                self.states.append(state)\n",
    "                self.nodes.append(current_GMM)\n",
    "                current_GMM=current_GMM.children[0]\n",
    "            state+=1\n",
    "            self.states.append(state)\n",
    "            self.nodes.append(current_GMM)\n",
    "    \n",
    "    def idx2words(self,result):\n",
    "        sentence=\"\"\n",
    "        for idx in result:\n",
    "            sentence+=self.nodes[idx].word\n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def traceback4or7(self,z_level,c):\n",
    "        if len(z_level)>=7:\n",
    "            min7=min(z_level[6][self.word_ends,c])\n",
    "            min4=min(z_level[3][self.word_ends,c])\n",
    "            \n",
    "            if min7<min4:\n",
    "                start=6\n",
    "            else:\n",
    "                start=3\n",
    "        else:\n",
    "            start=3\n",
    "            \n",
    "        final_result=\"\"\n",
    "        for i in range(start,-1,-1):\n",
    "            current_digit,c=self._traceback(z_level[i],c)\n",
    "            final_result=current_digit+final_result\n",
    "        return final_result\n",
    "    \n",
    "    def traceback(self,z_matrix,c):\n",
    "\n",
    "        final_result=\"\"\n",
    "        while c>0:\n",
    "            current_digit,c=self._traceback(z_matrix,c)\n",
    "            #print(current_digit)\n",
    "            final_result=current_digit+final_result\n",
    "\n",
    "        return final_result\n",
    "    \n",
    "    def _traceback(self,z_matrix,c):\n",
    "        min_idx=np.argmin(z_matrix[self.word_ends,c])\n",
    "        #print(min_idx)\n",
    "        r=self.word_ends[min_idx]\n",
    "        while r>0 and c>0:\n",
    "            to_check=[z_matrix[r,c-1], \n",
    "            z_matrix[self.get_parent[r],c-1],]\n",
    "            track=np.argmin(to_check)\n",
    "            if track==0:\n",
    "                c-=1\n",
    "            elif track==1:\n",
    "                c-=1\n",
    "                r=self.get_parent[r]\n",
    "            else:\n",
    "                r=self.get_parent[r]\n",
    "\n",
    "        #print(\"current word start from {} th input\".format(result))\n",
    "        return self.nodes[self.word_ends[min_idx]].word,c\n",
    "    \n",
    "    \n",
    "    def digit_vertibe47(self,data,loop_cost=300):\n",
    "        #set different types of cost\n",
    "        \n",
    "        loop_cost = loop_cost\n",
    "        \n",
    "        \n",
    "        zero39=np.zeros([data.shape[1]])\n",
    "        data=np.vstack([zero39,data])\n",
    "        # initialize cost matrix\n",
    "        n_cols = len(data)\n",
    "        n_rows = len(self.nodes)\n",
    "        costs = np.full([n_rows,n_cols], np.inf)\n",
    "        mute=np.zeros(n_rows)\n",
    "        # * to all other nodes\n",
    "        initial_cost=copy.deepcopy(costs)\n",
    "        initial_cost[0,0]=0\n",
    "\n",
    "\n",
    "        y_level=[mute]\n",
    "        z_level=[initial_cost]\n",
    "        for c in range(1,n_cols):\n",
    "            \n",
    "            next_y_level=[]\n",
    "            for current_possible_choice in range(len(z_level)):\n",
    "                z_matrix=z_level[current_possible_choice]\n",
    "                current_nodes=y_level[current_possible_choice]\n",
    "                next_to_check_nodes=copy.deepcopy(mute)\n",
    "                #update the y level costs\n",
    "                for r in range(1,n_rows):\n",
    "                    distance=mixture_log_gaussian(self.nodes[r].val,data[c])\n",
    "                    \n",
    "                    if current_nodes[r]:\n",
    "                        to_check=[( z_matrix[self.get_parent[r]][c-1]+\n",
    "                            self.transition_cost[self.nodes[r].word][self.states[self.get_parent[r]]][self.states[r]]\n",
    "                            )]\n",
    "                    elif current_nodes[self.get_parent[r]]:\n",
    "                        to_check=[z_matrix[r][c-1]+self.transition_cost[self.nodes[r].word][self.states[r]][self.states[r]]]\n",
    "                    elif current_nodes[self.get_parent[r]] and current_nodes[r]:\n",
    "                        to_check=[np.inf]\n",
    "                        next_to_check_nodes[r]=1\n",
    "                    else:\n",
    "                        to_check=[z_matrix[r][c-1]+self.transition_cost[self.nodes[r].word][self.states[r]][self.states[r]], # self transition\n",
    "                                 (z_matrix[self.get_parent[r]][c-1]+\n",
    "                                self.transition_cost[self.nodes[r].word][self.states[self.get_parent[r]]][self.states[r]])]\n",
    "\n",
    "                    z_matrix[r][c]= min(to_check)+distance\n",
    "                    if distance>500:#建议设置成500， 不然出错的几率会变大\n",
    "                        next_to_check_nodes[r]=1\n",
    "                next_y_level.append(next_to_check_nodes)\n",
    "                #现在查看是否有新的词可以产生\n",
    "                min_idx=np.argmin(z_matrix[:,c])\n",
    "                min_cost=min(z_matrix[:,c])\n",
    "                #print(\"min cost is {}, idx is {}\".format(min_cost,min_idx))\n",
    "                if min_idx in self.word_ends:\n",
    "                    if len(z_level)-1>current_possible_choice:\n",
    "                        #说明已经存在了这个新词\n",
    "                        next_z=z_level[current_possible_choice+1]\n",
    "                        next_z[0,c]=min_cost+loop_cost\n",
    "                        \n",
    "                    elif len(z_level)<7:\n",
    "                        #可以开新词\n",
    "                        new_z_matrix=copy.deepcopy(costs)\n",
    "                        new_z_matrix[0,c]=min_cost+loop_cost\n",
    "                        z_level.append(new_z_matrix)\n",
    "                        next_y_level.append(copy.deepcopy(mute))\n",
    "                                       \n",
    "            y_level=next_y_level\n",
    "        \n",
    "        final_result=self.traceback4or7(z_level,c)\n",
    "        print(\"final_result is {}\".format(final_result))\n",
    "        return final_result\n",
    "    \n",
    "    \n",
    "    def digit_vertibe(self,data,threshold=400,loop_cost=300):\n",
    "        #set different types of cost        \n",
    "        loop_cost = loop_cost\n",
    "        \n",
    "        zero39=np.zeros([data.shape[1]])\n",
    "        data=np.vstack([zero39,data])\n",
    "        # initialize cost matrix\n",
    "        n_cols = len(data)\n",
    "        n_rows = len(self.nodes)\n",
    "        trellis = np.full([n_rows,n_cols], np.inf)\n",
    "        trellis[0][0]=0\n",
    "        def pruning(column,threshold):\n",
    "            best=min(column)\n",
    "            for i in range(len(column)):\n",
    "                if column[i]>best+threshold:\n",
    "                    column[i]= np.inf\n",
    "        \n",
    "        for c in range(1,n_cols):\n",
    "            # pruning\n",
    "            if c>=3:\n",
    "                column=trellis[:,c-1]\n",
    "                pruning(column,threshold)\n",
    "            for r in range(1,n_rows):\n",
    "                distance=mixture_log_gaussian(self.nodes[r].val,data[c])\n",
    "\n",
    "                #to check information\n",
    "                to_check=[trellis[r][c-1]+self.transition_cost[self.nodes[r].word][self.states[r]][self.states[r]], # self transition\n",
    "                         (trellis[self.get_parent[r]][c-1]+\n",
    "                        self.transition_cost[self.nodes[r].word][self.states[self.get_parent[r]]][self.states[r]])]\n",
    "                \n",
    "                if not min (to_check)==np.inf:\n",
    "                    trellis[r][c]= min(to_check)+distance\n",
    "                \n",
    "            #现在查看是否有新的词可以产生\n",
    "            min_idx=np.argmin(trellis[:,c])\n",
    "            min_cost=min(trellis[:,c])\n",
    "            #print(\"min cost is {}, idx is {}\".format(min_cost,min_idx))\n",
    "            if min_idx in self.word_ends and min_cost!=np.inf:\n",
    "                #print(\"a new word start\")\n",
    "                trellis[0,c]=min_cost+loop_cost\n",
    "        \n",
    "        final_result=self.traceback(trellis,c)\n",
    "        print(\"final_result is {}\".format(final_result))\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr=ContinousSpeechRecognition()\n",
    "csr.fit(lextree,transition_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result is 2347575\n",
      "Recognize 2347895 as 2347575\n",
      "final_result is 2212\n",
      "Recognize 2212 as 2212\n",
      "final_result is 6575\n",
      "Recognize 5678 as 6575\n",
      "final_result is 6398\n",
      "Recognize 6398 as 6398\n",
      "final_result is 0751\n",
      "Recognize 3785 as 0751\n",
      "final_result is 6181\n",
      "Recognize 6789 as 6181\n",
      "final_result is 1324711\n",
      "Recognize 3247895 as 1324711\n",
      "final_result is 3657855\n",
      "Recognize 3657895 as 3657855\n",
      "final_result is 1234567\n",
      "Recognize 1234567 as 1234567\n",
      "final_result is 1647511\n",
      "Recognize 8647895 as 1647511\n",
      "final_result is 9395\n",
      "Recognize 1398 as 9395\n",
      "final_result is 1399\n",
      "Recognize 1399 as 1399\n",
      "final_result is 1521755\n",
      "Recognize 3217895 as 1521755\n",
      "final_result is 4511\n",
      "Recognize 4391 as 4511\n",
      "final_result is 6657511\n",
      "Recognize 8657895 as 6657511\n",
      "final_result is 1399\n",
      "Recognize 7398 as 1399\n",
      "final_result is 2345678\n",
      "Recognize 2345678 as 2345678\n",
      "final_result is 9395\n",
      "Recognize 5398 as 9395\n",
      "final_result is 9399\n",
      "Recognize 9398 as 9399\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_folder=\"test_data/problem1/\"\n",
    "wavefiles=os.listdir(file_folder)\n",
    "\n",
    "for wavefile in wavefiles:\n",
    "    digit=wavefile[:-4]\n",
    "    data=getMFCC2(file_folder+wavefile)\n",
    "    digit_result=csr.digit_vertibe47(data)\n",
    "    print(\"Recognize {} as {}\".format(digit,digit_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result is 85555\n",
      "Recognize 55555 as 85555\n",
      "final_result is 7343332190371\n",
      "Recognize 7343332190377 as 7343332190371\n",
      "final_result is 101385\n",
      "Recognize 911385 as 101385\n",
      "final_result is 6800372344\n",
      "Recognize 6890372344 as 6800372344\n",
      "final_result is 721814547124\n",
      "Recognize 72184347924 as 721814547124\n",
      "final_result is 29675543\n",
      "Recognize 25678543 as 29675543\n",
      "final_result is 923456\n",
      "Recognize 123456 as 923456\n",
      "final_result is 28212776342\n",
      "Recognize 8212176342 as 28212776342\n",
      "final_result is 37274121\n",
      "Recognize 37274921 as 37274121\n",
      "final_result is 0825414052002\n",
      "Recognize 826414052002 as 0825414052002\n"
     ]
    }
   ],
   "source": [
    "file_folder=\"test_data/problem2/\"\n",
    "wavefiles=os.listdir(file_folder)\n",
    "\n",
    "for wavefile in wavefiles:\n",
    "    digit=wavefile[:-4]\n",
    "    data=getMFCC2(file_folder+wavefile)\n",
    "    digit_result=csr.digit_vertibe(data)\n",
    "    print(\"Recognize {} as {}\".format(digit,digit_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
